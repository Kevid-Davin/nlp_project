,language,readme_contents,repo
0,Clojure,"# Advent of Code

[Advent of Code](http://adventofcode.com) in Clojure and Self-Hosted ClojureScript.

## Clojure

```
clj
```

## Self-Hosted ClojureScript

```
plk
```
",mfikes/advent-of-code
1,Kotlin,"# Advent of Code 2017

Here's a blank template for working on the [Advent of Code (2017)](http://adventofcode.com/2017). It's got all the
tests you could possibly want with the answers obscured. Just work your way through the puzzles until all the tests
pass!

You can find the puzzle questions [here](http://adventofcode.com/2017).

You can find my answers [here](https://github.com/dlew/aoc-2017/tree/answers). I make no claim to them being any good,
only that they arrive at the correct answer.

[@danlew42](https://twitter.com/danlew42)
",dlew/aoc-2017
2,Haskell,"Advent of Code 2017
===================

*[2016][]* / *2017* / *[2018][]* / *[2019][]*

[2016]: https://github.com/mstksg/advent-of-code-2016
[2018]: https://github.com/mstksg/advent-of-code-2018
[2019]: https://github.com/mstksg/advent-of-code-2019

**Warning: Spoilers**

[Reflections and Benchmarks][RnB]
---------------------------------

[RnB]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md

I try to reflect on every day's puzzle, attempting to describe my thought
processes and how my solutions all work.  Benchmarks also included.

*   **[Day 1 Reflections][d1r]** *([code][d1c])* *([benchmarks][d1b])*
*   **[Day 2 Reflections][d2r]** *([code][d2c])* *([benchmarks][d2b])*
*   **[Day 3 Reflections][d3r]** *([code][d3c])* *([benchmarks][d3b])*
*   **[Day 4 Reflections][d4r]** *([code][d4c])* *([benchmarks][d4b])*
*   **[Day 5 Reflections][d5r]** *([code][d5c])* *([benchmarks][d5b])*
*   **[Day 6 Reflections][d6r]** *([code][d6c])* *([benchmarks][d6b])*
*   **[Day 7 Reflections][d7r]** *([code][d7c])* *([benchmarks][d7b])*
*   **[Day 8 Reflections][d8r]** *([code][d8c])* *([benchmarks][d8b])*
*   **[Day 9 Reflections][d9r]** *([code][d9c])* *([benchmarks][d9b])* *([stream][d9s])*
*   **[Day 10 Reflections][d10r]** *([code][d10c])* *([benchmarks][d10b])* *([stream][d10s])*
*   **[Day 11 Reflections][d11r]** *([code][d11c])* *([benchmarks][d11b])*
*   **[Day 12 Reflections][d12r]** *([code][d12c])* *([benchmarks][d12b])*
*   **[Day 13 Reflections][d13r]** *([code][d13c])* *([benchmarks][d13b])*
*   **[Day 14 Reflections][d14r]** *([code][d14c])* *([benchmarks][d14b])*
*   **[Day 15 Reflections][d15r]** *([code][d15c])* *([benchmarks][d15b])*
*   **[Day 16 Reflections][d16r]** *([code][d16c])* *([benchmarks][d16b])*
*   **[Day 17 Reflections][d17r]** *([code][d17c])* *([benchmarks][d17b])*
*   **Day 18 Reflections** *([code][d18c])* *([benchmarks][d18b])*
*   **[Day 19 Reflections][d19r]** *([code][d19c])* *([benchmarks][d19b])*
*   **Day 20 Reflections** *([code][d20c])* *([benchmarks][d20b])*
*   **Day 21 Reflections** *([code][d21c])* *([benchmarks][d21b])*
*   **Day 22 Reflections** *([code][d22c])* *([benchmarks][d22b])*
*   **Day 23 Reflections** *([code][d23c])* *([benchmarks][d23b])*
*   **Day 24 Reflections** *([code][d24c])* *([benchmarks][d24b])*
*   **Day 25 Reflections** *([code][d25c])* *([benchmarks][d25b])*

[d1r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-1
[d2r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-2
[d3r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-3
[d4r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-4
[d5r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-5
[d6r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-6
[d7r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-7
[d8r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-8
[d9r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-9
[d10r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-10
[d11r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-11
[d12r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-12
[d13r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-13
[d14r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-14
[d15r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-15
[d16r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-16
[d17r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-17
[d18r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-18
[d19r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-19
[d20r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-20
[d21r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-21
[d22r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-22
[d23r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-23
[d24r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-24
[d25r]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-25

[d1c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day01.hs
[d2c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day02.hs
[d3c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day03.hs
[d4c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day04.hs
[d5c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day05.hs
[d6c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day06.hs
[d7c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day07.hs
[d8c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day08.hs
[d9c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day09.hs
[d10c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day10.hs
[d11c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day11.hs
[d12c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day12.hs
[d13c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day13.hs
[d14c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day14.hs
[d15c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day15.hs
[d16c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day16.hs
[d17c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day17.hs
[d18c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day18.hs
[d19c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day19.hs
[d20c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day20.hs
[d21c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day21.hs
[d22c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day22.hs
[d23c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day23.hs
[d24c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day24.hs
[d25c]: https://github.com/mstksg/advent-of-code-2017/blob/master/src/AOC2017/Day25.hs

[d1b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-1-benchmarks
[d2b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-2-benchmarks
[d3b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-3-benchmarks
[d4b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-4-benchmarks
[d5b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-5-benchmarks
[d6b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-6-benchmarks
[d7b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-7-benchmarks
[d8b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-8-benchmarks
[d9b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-9-benchmarks
[d10b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-10-benchmarks
[d11b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-11-benchmarks
[d12b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-12-benchmarks
[d13b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-13-benchmarks
[d14b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-14-benchmarks
[d15b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-15-benchmarks
[d16b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-16-benchmarks
[d17b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-17-benchmarks
[d18b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-18-benchmarks
[d19b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-19-benchmarks
[d20b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-20-benchmarks
[d21b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-21-benchmarks
[d22b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-22-benchmarks
[d23b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-23-benchmarks
[d24b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-24-benchmarks
[d25b]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md#day-25-benchmarks

[d9s]: https://www.twitch.tv/videos/207969022
[d10s]: https://www.twitch.tv/videos/208287550

Executable
----------

Comes with test examples given in problems.

You can install using `stack`:

```bash
$ git clone https://github.com/mstksg/advent-of-code-2017
$ cd advent-of-code-2017
$ stack setup
$ stack install
```

The executable `aoc2017` includes a testing and benchmark suite

```
$ aoc2017 --help
aoc2017 - Advent of Code 2017 challenge runner

Usage: aoc2017 DAY [PART] [-t|--tests] [-b|--bench]
  Run challenges from Advent of Code 2017

Available options:
  DAY                      Day of challenge (1 - 25), or ""all""
  PART                     Challenge part (a, b, c, etc.)
  -t,--tests               Run sample tests
  -b,--bench               Run benchmarks
  -h,--help                Show this help text

$ aoc2017 5 b
>> Day 05b
>> [✓] 27720699
```

Benchmarking is implemented using *criterion*

```
$ aoc2017 2 --bench
>> Day 02a
benchmarking...
time                 729.1 μs   (695.0 μs .. 784.2 μs)
                     0.967 R²   (0.926 R² .. 0.995 R²)
mean                 740.4 μs   (711.9 μs .. 783.6 μs)
std dev              116.8 μs   (70.44 μs .. 172.8 μs)
variance introduced by outliers: 89% (severely inflated)

>> Day 02b
benchmarking...
time                 782.4 μs   (761.3 μs .. 812.9 μs)
                     0.983 R²   (0.966 R² .. 0.998 R²)
mean                 786.7 μs   (764.1 μs .. 849.4 μs)
std dev              110.8 μs   (42.44 μs .. 228.5 μs)
variance introduced by outliers: 86% (severely inflated)
```

Test suites run the example problems given in the puzzle description, and
outputs are colorized in ANSI terminals.

```
$ aoc2017 1 --tests
[9] [!35732] $ aoc2017 1 --tests
>> Day 01a
[✓] (3)
[✓] (4)
[✓] (0)
[✓] (9)
[✓] Passed 4 out of 4 test(s)
[✓] 1097
>> Day 01b
[✓] (6)
[✓] (0)
[✓] (4)
[✓] (12)
[✓] (4)
[✓] Passed 5 out of 5 test(s)
[✓] 1188
```

This should only work if you're running `aoc2017` in the project directory.

**To run on actual inputs**, the executable expects inputs to be found in the
folder `data/XX.txt` in the directory you are running in.  That is, the input
for Day 7 will be expected at `data/07.txt`.

*aoc2017 will download missing input files*, but requires a session token.
This can be provided in `aoc2017-conf.yaml`:

```yaml
session:  [[ session token goes here ]]
```

You can ""lock in"" your current answers (telling the executable that those are
the correct answers) by passing in `--lock`.  This will lock in any final
puzzle solutions encountered as the verified official answers.  Later, if you
edit or modify your solutions, they will be checked on the locked-in answers.

These are store in `data/ans/XXpart.txt`.  That is, the target output for Day 7
(Part 2, `b`) will be expected at `data/ans/07b.txt`.  You can also manually
edit these files.

",mstksg/advent-of-code-2017
3,Python,"# Advent of code 2017 #
Bidra med dina lösningar på problemen i [Advent of code](http://adventofcode.com/), i vilket språk du vill. Välj ett du kan, eller ett du vill lära dig!

Se till att du går med i advent of code's topplista om du vill ha en chans att vinna kodsnack's tävling. Vårat topplista har ID: `194162-e06e748d`. Det finns även en slack kanal för alla som är med. Maila info@kodsnack.se eller twittra din epost till @kodsnack så släpper vi in er.

De första problemen kommer första december, de sista den tjugofemte, och vi delar ut ett pris till den eller de som dels har högst poäng på den leaderboard vi kommer att skapa, dels bidragit med alla sin lösningar här. Som förra året är det två delproblem för varje dag. Samtliga 50 problem ska alltså finnas med i en komplett lösning. Det är givetvis fritt fram att bidra med lösningar för så många eller få problem man har tid och lust med, tävlingsmomentet är inte det viktiga här!

Dina lösningar får gärna checkas in i en mapp med namn på formen #användarnamn-språk#, så blir det lite lättare för alla att få överblick.

Lösningarna kan komma att diskuteras i avsnitt av Kodsnack, så lägg med en readme.md med en notis om du inte vill riskera att bli omnämnd.
",kodsnack/advent_of_code_2017
4,Rust,,Diggsey/aoc2018
5,Haskell,"Advent of Code 2019
=====================

<!--
This file generated by the build script at ./Build.hs
-->

*[2016][]* / *[2017][]* / *[2018][]* / *2019*

[2016]: https://github.com/mstksg/advent-of-code-2016
[2017]: https://github.com/mstksg/advent-of-code-2017
[2018]: https://github.com/mstksg/advent-of-code-2018

It's the most wonderful time of the year!

My [Advent of Code 2019][aoc] Haskell solutions here, along with an automated
fetching, testing, running environment (powered by the
*[advent-of-code-api][]* library).  The interactive development environment and
runner/bench marker/viewer/tester has been pulled out [here][dev], so this is
implemented as ""fork"" of it with my own solutions and reflections.

Check out the [reflections][] (with [rss feed][rss]) and [package
haddocks][haddock] --- more info below!

[aoc]: https://adventofcode.com/2019
[haddock]: https://mstksg.github.io/advent-of-code-2019/
[advent-of-code-api]: https://hackage.haskell.org/package/advent-of-code-api
[dev]: https://github.com/mstksg/advent-of-code-dev

[Reflections and Benchmarks][reflections]
-----------------------------------------

[Available as RSS Feed][rss]

[rss]: http://feeds.feedburner.com/jle-advent-of-code-2019

| Challenge | Reflections | Code      | Rendered   | Benchmarks |
| --------- | ----------- | --------- | ---------- | ---------- |
| Day  1    | [x][d01r]   | [x][d01g] | [x][d01h]  | [x][d01b]  |
| Day  2    | [x][d02r]   | [x][d02g] | [x][d02h]  | [x][d02b]  |
| Day  3    | [x][d03r]   | [x][d03g] | [x][d03h]  | [x][d03b]  |
| Day  4    | [x][d04r]   | [x][d04g] | [x][d04h]  | [x][d04b]  |
| Day  5    |             |           |            |            |
| Day  6    | [x][d06r]   | [x][d06g] | [x][d06h]  | [x][d06b]  |
| Day  7    |             |           |            |            |
| Day  8    | [x][d08r]   | [x][d08g] | [x][d08h]  | [x][d08b]  |
| Day  9    |             |           |            |            |
| Day 10    | [x][d10r]   | [x][d10g] | [x][d10h]  | [x][d10b]  |
| Day 11    |             |           |            |            |
| Day 12    |             |           |            |            |
| Day 13    |             |           |            |            |
| Day 14    |             |           |            |            |
| Day 15    |             |           |            |            |
| Day 16    |             |           |            |            |
| Day 17    |             |           |            |            |
| Day 18    |             |           |            |            |
| Day 19    |             |           |            |            |
| Day 20    |             |           |            |            |
| Day 21    |             |           |            |            |
| Day 22    |             |           |            |            |
| Day 23    |             |           |            |            |
| Day 24    |             |           |            |            |
| Day 25    |             |           |            |            |

""Rendered"" links go to haddock source renders for code, with reflections in the
documentation.  Haddock source renders have hyperlinked identifiers,
so you can follow any unrecognized identifiers to see where I have defined them
in the library.

[reflections]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md

### `:~>` type

If you're looking at my actual github solutions, you'll notice that this year
I'm implementing my solutions in terms of a `:~>` record type:

```haskell
data a :~> b = MkSol
    { sParse :: String -> Maybe a    -- ^ parse input into an `a`
    , sSolve :: a      -> Maybe b    -- ^ solve an `a` input to a `b` solution
    , sShow  :: b      -> String     -- ^ print out the `b` solution for submission
    }
```

An `a :~> b` is a solution to a challenge expecting input of type `a` and
producing answers of type `b`.  It also packs in functions to parse a `String`
into an `a`, and functions to show a `b` as a `String` to submit as an answer.

This helps me mentally separate out parsing, solving, and showing, allowing for
some cleaner code and an easier time planning my solution.

Such a challenge can be ""run"" on string inputs by feeding the string into
`sParse`, then `sSolve`, then `sShow`:

```haskell
-- | Run a ':~>' on some input, retuning 'Maybe'
runSolution :: Challenge -> String -> Maybe String
runSolution MkSol{..} s = do
    x <- sParse s
    y <- sSolve x
    pure (sShow y)
```

In the actual library, I have `runSolution` return an `Either` so I can debug
which stage the error happened in.

You might also notice the function `dyno_`, used like `dyno_ ""limit"" 10000`.  This
is how I implement parameters in problems that vary between test data and
actual input.  For example, Day 6 involved finding points that had a total
distance of less than 10000, but for the test input, we found the points that
had a total distance of less than 32.  So, I have a system that lets me write
`dyno_ ""limit"" 10000` in my code instead of hard-coding in `10000`.  This
`10000` would be replaced by `32` when running with test data (which is parsed
from [this file][7btest])

[7btest]: https://github.com/mstksg/advent-of-code-2018/blob/master/test-data/06b.txt

Interactive
-----------

The *[AOC.Run.Interactive][interactive]* module has code (powered by
*[advent-of-code-api][]*) for testing your solutions and submitting within
GHCI, so you don't have to re-compile. If you edit your solution programs, they
are automatically updated when you hit `:r` in ghci.

[interactive]: https://mstksg.github.io/advent-of-code-2019/AOC2019-Run-Interactive.html

```haskell
ghci> execSolution_   $ solSpec 'day02a   -- get answer for challenge based on solution
ghci> testSolution_   $ solSpec 'day02a   -- run solution against test suite
ghci> viewPrompt_     $ solSpec 'day02a   -- view the prompt for a part
ghci> waitForPrompt_  $ solSpec 'day02a   -- count down to the prompt for a part
ghci> submitSolution_ $ solSpec 'day02a   -- submit a solution
```

These are loaded with session key stored in the configuration file (see next
section).

Executable
----------

Comes with test examples given in problems.

You can install using `stack`:

```bash
$ git clone https://github.com/mstksg/advent-of-code-2019
$ cd advent-of-code-2019
$ stack setup
$ stack install
```

The executable `aoc2019` includes a testing and benchmark suite, as well as a
way to view prompts within the command line:

```
$ aoc2019 --help
aoc2019 - Advent of Code 2019 challenge runner

Usage: aoc2019 [-c|--config PATH] COMMAND
  Run challenges from Advent of Code 2019. Available days: 1, 2, 3 (..)

Available options:
  -c,--config PATH         Path to configuration file (default: aoc-conf.yaml)
  -h,--help                Show this help text

Available commands:
  run                      Run, test, and benchmark challenges
  view                     View a prompt for a given challenge
  submit                   Test and submit answers for challenges
  test                     Alias for run --test
  bench                    Alias for run --bench
  countdown                Alias for view --countdown

$ aoc2019 run 3 b
>> Day 03b
>> [✓] 243
```

You can supply input via stdin with `--stdin`:

```
$ aoc2019 run 1 --stdin
>> Day 01a
+1
+2
+1
-3
<Ctrl+D>
[?] 1
>> Day 01b
[?] 1
```

Benchmarking is implemented using *criterion*

```
$ aoc2019 bench 2
>> Day 02a
benchmarking...
time                 1.317 ms   (1.271 ms .. 1.392 ms)
                     0.982 R²   (0.966 R² .. 0.999 R²)
mean                 1.324 ms   (1.298 ms .. 1.373 ms)
std dev              115.5 μs   (77.34 μs .. 189.0 μs)
variance introduced by outliers: 65% (severely inflated)

>> Day 02b
benchmarking...
time                 69.61 ms   (68.29 ms .. 72.09 ms)
                     0.998 R²   (0.996 R² .. 1.000 R²)
mean                 69.08 ms   (68.47 ms .. 69.99 ms)
std dev              1.327 ms   (840.8 μs .. 1.835 ms)
```

Test suites run the example problems given in the puzzle description, and
outputs are colorized in ANSI terminals.

```
$ aoc2019 test 1
>> Day 01a
[✓] (3)
[✓] (3)
[✓] (0)
[✓] (-6)
[✓] Passed 4 out of 4 test(s)
[✓] 416
>> Day 01b
[✓] (2)
[✓] (0)
[✓] (10)
[✓] (5)
[✓] (14)
[✓] Passed 5 out of 5 test(s)
[✓] 56752
```

This should only work if you're running `aoc2019` in the project directory.

**To run on actual inputs**, the executable expects inputs to be found in the
folder `data/XX.txt` in the directory you are running in.  That is, the input
for Day 7 will be expected at `data/07.txt`.

*aoc2019 will download missing input files*, but requires a session token.
This can be provided in `aoc-conf.yaml`:

```yaml
session:  [[ session token goes here ]]
```

Session keys are also required to download ""Part 2"" prompts for each challenge.

You can ""lock in"" your current answers (telling the executable that those are
the correct answers) by passing in `--lock`.  This will lock in any final
puzzle solutions encountered as the verified official answers.  Later, if you
edit or modify your solutions, they will be checked on the locked-in answers.

These are stored in `data/ans/XXpart.txt`.  That is, the target output for Day 7
(Part 2, `b`) will be expected at `data/ans/07b.txt`.  You can also manually
edit these files.

You can view prompts: (use `--countdown` to count down until a prompt is
released, and display immediately)

```
$ aoc2019 view 3 b
>> Day 03b
--- Part Two ---
----------------

Amidst the chaos, you notice that exactly one claim doesn't overlap by
even a single square inch of fabric with any other claim. If you can
somehow draw attention to it, maybe the Elves will be able to make
Santa's suit after all!

For example, in the claims above, only claim `3` is intact after all
claims are made.

*What is the ID of the only claim that doesn't overlap?*
```

You can also submit answers:

```
$ aoc2019 submit 1 a
```

Submissions will automatically run the test suite.  If any tests fail, you will
be asked to confirm submission or else abort.  The submit command will output
the result of your submission: The message from the AoC website, and whether or
not your answer was correct (or invalid or ignored).  Answers that are
confirmed correct will be locked in and saved for future testing against, in
case you change your solution.

All networking features are powered by *[advent-of-code-api][]*.

[d01g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day01.hs
[d01h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day01.html
[d01r]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-1
[d01b]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-1-benchmarks
[d02g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day02.hs
[d02h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day02.html
[d02r]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-2
[d02b]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-2-benchmarks
[d03g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day03.hs
[d03h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day03.html
[d03r]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-3
[d03b]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-3-benchmarks
[d04g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day04.hs
[d04h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day04.html
[d04r]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-4
[d04b]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-4-benchmarks
[d06g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day06.hs
[d06h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day06.html
[d06r]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-6
[d06b]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-6-benchmarks
[d08g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day08.hs
[d08h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day08.html
[d08r]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-8
[d08b]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-8-benchmarks
[d10g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day10.hs
[d10h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day10.html
[d10r]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-10
[d10b]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md#day-10-benchmarks
",mstksg/advent-of-code-2019
6,Elixir,"# Advent of Code Elixir Starter

A batteries included starter pack for participating in [Advent of Code](https://www.adventofcode.com) using Elixir!

## Usage

There are 25 modules, 25 tests, and 50 mix tasks. 

1. Fill in the tests with the example solutions.
1. Write your implementation.
1. Fill in the final problem inputs into the mix task and run `mix d01.p1`!
    - Benchmark your solution by passing the `-b` flag, `mix d01.p1 -b`

```elixir
defmodule AdventOfCode.Day01 do
  def part1(args) do
  end

  def part2(args) do
  end
end
```

```elixir
defmodule AdventOfCode.Day01Test do
  use ExUnit.Case

  import AdventOfCode.Day01

  @tag :skip # Make sure to remove to run your test.
  test ""part1"" do
    input = nil 
    result = part1(input)

    assert result
  end

  @tag :skip # Make sure to remove to run your test.
  test ""part2"" do
    input = nil 
    result = part2(input)

    assert result
  end
end
```

```elixir
defmodule Mix.Tasks.D01.P1 do
  use Mix.Task

  import AdventOfCode.Day01

  @shortdoc ""Day 01 Part 1""
  def run(args) do
    input = nil

    if Enum.member?(args, ""-b""),
      do: Benchee.run(%{part_1: fn -> input |> part1() end}),
      else:
        input
        |> part1()
        |> IO.inspect(label: ""Part 1 Results"")
  end
end   
```

## Installation

```bash
# clone
$ git clone git@github.com:mhanberg/advent-of-code-elixir-starter.git advent-of-code
$ cd advent-of-code

# Reinitialize your git repo
$ rm -rf .git
$ git init
```
",mhanberg/advent-of-code-elixir-starter
7,Clojure,"# Advent of CLJC
[![CircleCI](https://circleci.com/gh/borkdude/advent-of-cljc/tree/master.svg?style=svg)](https://circleci.com/gh/borkdude/advent-of-cljc/tree/master)

Cross platform Clojure Advent of Code solutions.

<img src=""doc/scores.png"" alt=""scores"" width=""50%""/>

## Contribute

What's in it for you?
* Most of all, you will be encouraged to write portable Clojure code: a solution that runs on the JVM via Clojure and on Node via ClojureScript.
* Your Advent of Code solutions will be checked against the same input as others. This diminishes the possibility that your solution only works for your specific input.
* The performance of your solution can be compared with others via CircleCI (see [Scores](#scores)).

What's in it for the Clojure community?
* You are helping advance the [speculative](https://github.com/slipset/speculative) project, a collection of core specs.
* You are helping to build a large Clojure corpus for various purposes (see the Rationale for [coal-mine](https://github.com/mfikes/coal-mine)).

PRs welcome. Make a new solution file with the `new` script:

    script/new 2017 1 username

where `username` is your Github or Bitbucket username. Then fill in the solution in the file. If the input and answers are still empty you will have to provide it in `data.cljc`.

This repo will not accept multiple inputs and answers (see [this issue](https://github.com/borkdude/advent-of-cljc/issues/6) for details).

## Dev

Read [here](https://nrepl.xyz/nrepl/usage/server.html) how to get an nREPL for this project.

## Tests

Make sure the tests for your solution pass with the `test-one` script.

Please do not run calculations outside the tests. Memoized functions are permitted. Top-level lazy sequences are fine as long as they are not realized outside the tests.

CircleCI runs tests for changed namespaces with the `.circle/test-diff` script.

Tests support the following metadata:

 - `:skip-cljs`: used for skipping Node tests. Used in `.circle/test-diff`,
   `script/test` and `script/test-one`.
 - `:skip`: used for skipping tests in `script/test`.

Run all tests:

    script/test

Run one test:

    script/test-one 2017 1 username
    
Run with instrumentation:

    INSTRUMENT=true script/test
    INSTRUMENT=true script/test-one aoc.y2017.d01.username

Skip Clojure or ClojureScript:

    SKIP_CLJ=true script/test
    SKIP_CLJS=true script/test

## Scores

To view a time comparison of your solutions to others, go to
[CircleCI](https://circleci.com/gh/borkdude/advent-of-cljc/tree/master), open
""Test changed namespaces"" and scroll to the end.

The entire list of scores can be viewed and downloaded in CSV format
[here](https://gist.github.com/borkdude/d7f42d4110e8a330d1d70f9242b14496).
",borkdude/advent-of-cljc
8,Haskell,"# AofC2017
Advent of Code 2017
",BartoszMilewski/AofC2017
9,,"# Advent of Code 2019 (coding_challenge-24)

![](./aoc.png)

# What is Advent of Code?
> Advent of Code is an Advent calendar of small programming puzzles for a variety of skill sets and skill levels that can be solved in any programming language you like **yes, including JavaScript and Python!!!**
> Every day for 25 days this month you have small programming challenges that you need to solve to complete the ""tree"". Each day, the questions get a little bit harder to really push you to learn and improve your programming skills.

We have created a special area for the ZTM community to share their solutions and code each day, see what others have done, and vote for your favourite solution. We even have a leaderboard!

# How to participate:
### (This event starts December 1st, 2019 but you can join anytime. Solutions submitted on the day of the of the puzzle reveal will receive extra points!)
1. Go to https://aoc.zerotomastery.io/ and click on the **ABOUT** to find out more about the challenge and how to participate.
2. Go to https://adventofcode.com/ and start with problem #1! Each day starting Dec 1st, 2019 a new problem will be unlocked but you have to do them in order!
3. Once you finish one puzzle/question, you can share your code and solution with the community, or check out what others in the ZTM community have done. You can even vote on your favourite solutions! You can [follow this video on how to submit your solution](https://www.loom.com/share/7310b6e83bcc4922b25023b62d173611).
4. Check out the leaderboard and see how you compare: https://aoc.zerotomastery.io/leaderboard
5. **Bonus**: In case you get stuck, I made 2 videos available for free preview for you to show you how I solve one of the problems and the steps I take. Simply go to the [Complete Web Developer in 2020: Zero to Mastery](https://www.udemy.com/course/the-complete-web-developer-zero-to-mastery/?referralCode=FFF295AECF3594CE440E) course and check out the two lectures (*Exercise: Santa's Node Helper* and *Solution: Santas Node Helper*). Even if you are not enrolled in the course these two videos have the free preview option enabled). 

**You can discuss all AOC related topics in our #coding-challenge channel on Discord!**

# Who made this possible?
Some of our fellow ZTM members helped create this awesome platform to submit and share code. Give them a big thank you on Discord!
```
@Matt
@Dichotomyy
@E
@notAnkur
@Brittney
@Abdus
@Meet
```

## One Last Thing!

**Please note: As with all my challenges there is zero benefit or monetary gain I recieve from it. This is just my way of thanking my students and making sure that you are able to continue gaining valuable knowledge outside of just my videos. It would mean a lot to me if you are able to rate my course...5 star reviews make my day :)**

",zero-to-mastery/coding_challenge-24
