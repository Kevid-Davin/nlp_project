[{"repo": "Bogdanp/awesome-advent-of-code", "language": "Python", "readme_contents": "# Awesome Advent of Code\n\nThis is a collection of awesome resources related to the yearly\n[Advent of Code] challenge.\n\n[Advent of Code]: https://adventofcode.com/\n\n* [The Official AoC Website](https://adventofcode.com/)\n* [The AoC Subreddit](https://www.reddit.com/r/adventofcode/)\n* [Project Templates](#project-templates)\n* [Tools and Utilities](#tools-and-utilities)\n* [Other Advent Calendars](#other-advent-calendars)\n* [2018](/2018.md)\n* [2019](#2019)\n  * [Solutions](#solutions)\n    * [AWK](#awk)\n    * [Ada](#ada)\n    * [Bash](#Bash)\n    * [C](#c)\n    * [C#](#c-1)\n    * [C++](#c-2)\n    * [Clojure](#clojure)\n    * [Common Lisp](#common-lisp)\n    * [Crystal](#crystal)\n    * [D](#d)\n    * [Dart](#dart)\n    * [Elixir](#elixir)\n    * [Elm](#elm)\n    * [Erlang](#erlang)\n    * [F#](#f)\n    * [Go](#go)\n    * [Groovy](#groovy)\n    * [Haskell](#haskell)\n    * [Idris](#idris)\n    * [Java](#java)\n    * [JavaScript](#javascript)\n    * [Julia](#julia)\n    * [Kotlin](#kotlin)\n    * [LDPL](#ldpl)\n    * [Nim](#nim)\n    * [OCaml](#ocaml)\n    * [PHP](#php)\n    * [Perl](#perl)\n    * [Pony](#pony)\n    * [PowerShell](#powershell)\n    * [Python](#python)\n    * [R](#r)\n    * [Racket](#racket)\n    * [ReasonML](#reasonml)\n    * [Red](#red)\n    * [Ruby](#ruby)\n    * [Rust](#rust)\n    * [Smalltalk](#smalltalk)\n    * [Scala](#scala)\n    * [Scheme](#scheme)\n    * [Swift](#swift)\n    * [TypeScript](#typescript)\n    * [Zig](#zig)\n  * [Live Streams](#live-streams)\n\n---\n\n## Project Templates\n\n*Templates, cookiecutters and skeletons for quickly setting up projects\nin your favourite language.*\n\n* [dave-burke/advent-of-code-java-starter](https://github.com/dave-burke/advent-of-code-java-starter) *(Java)*\n* [gobanos/cargo-aoc](https://github.com/gobanos/cargo-aoc) *(Rust)*\n* [hughjdavey/aoc-kotlin-starter](https://github.com/hughjdavey/aoc-kotlin-starter) *(Kotlin)*\n* [kindermoumoute/adventofcode](https://github.com/kindermoumoute/adventofcode/tree/master/template) *(Go)*\n* [staylorwr/elixir_aoc](https://github.com/staylorwr/elixir_aoc) *(Elixir)*\n* [mhanberg/advent-of-code-elixir-starter](https://github.com/mhanberg/advent-of-code-elixir-starter) *(Elixir)*\n* [AlexeSimon/adventofcode](https://github.com/AlexeSimon/adventofcode) *(Python)*\n* [sindrekjr/AdventOfCodeBase](https://github.com/sindrekjr/AdventOfCodeBase) *(C#)*\n* [mhanberg/advent-of-code-clojure-starter](https://github.com/mhanberg/advent-of-code-clojure-starter) *(Clojure)*\n* [caderek/aoc-starter-js](https://github.com/caderek/aoc-starter-js) *(JavaScript)*\n* [caderek/aoc-starter-ts](https://github.com/caderek/aoc-starter-ts) *(TypeScript)*\n\n## Tools and Utilities\n\n* [Alfie](https://alfie.prodo.ai/) -- Online JS editor that helps users solve AoC problems.\n* [Chrome extension](https://chrome.google.com/webstore/detail/advent-of-code-ranking/jbnlafikncgjjhdkmfhokcplgahebmjl) -- Browser extension for private leaderboard visualization\n* [Firefox extension](https://addons.mozilla.org/en-US/firefox/addon/aoc-ranking/) -- Browser extension for private leaderboard visualization\n* [Globals medals overview](http://www.maurits.vdschee.nl/scatterplot/medals.html) -- Alternative global leaderboard showing first, second and third places as gold, silver and bronze medals.\n* [Scatterplot of first 100](http://www.maurits.vdschee.nl/scatterplot/) -- Scatterplot of the time taken to solve the parts of each puzzle by the first 100 people that solved it.\n* [aocdl](https://github.com/GreenLightning/advent-of-code-downloader) -- Command-line utility that automatically downloads your personal input file while you read the puzzle description *(Go)*.\n* [aoc-cli](https://github.com/keirua/aoc-cli) -- Command-line utility that helps solve problems in ruby: it downloads your personal input file, creates the sample source files and benchmarks your solutions *(Ruby)*.\n* [AoCHelper](https://github.com/eduherminio/AoCHelper) -- NuGet library that simplifies puzzle solving and provides benchmarking *(.NET)*.\n\n## Other Advent Calendars\n\n*24 days of cool stuff regarding <insert-technology-here>.*\n\n* [Perl6 Advent Calendar](https://perl6advent.wordpress.com/)\n* [QEMU Advent Calendar](https://www.qemu-advent-calendar.org/)\n\n## 2019\n\n**WARNING:** All of these likely contain spoilers.\n\nRead [CONTRIBUTING.md](/CONTRIBUTING.md) to learn how to add your own repos.\n\n### Solutions\n\n#### AWK\n\n*Solutions to AoC in AWK.*\n\n#### Ada\n\n*Solutions to AoC in Ada.*\n\n* [jamestomasino/advent-of-code-2019](https://github.com/jamestomasino/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/jamestomasino/advent-of-code-2019.svg)\n\n#### Bash\n\n*Solutions to AoC in Bash.*\n\n#### C\n\n*Solutions to AoC in C.*\n\n* [coder5506/advent-of-code-2019](https://github.com/coder5506/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/coder5506/advent-of-code-2019.svg)\n\n#### C#\n\n*Solutions to AoC in C#.*\n\n* [AnkurSheel/AdventOfCode2019](https://github.com/AnkurSheel/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/AnkurSheel/AdventOfCode2019.svg)\n* [alexchro93/AdventOfCode](https://github.com/alexchro93/AdventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/alexchro93/AdventOfCode.svg)\n* [eduherminio/AoC2019](https://github.com/eduherminio/AoC2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/eduherminio/AoC2019.svg)\n* [encse/adventofcode](https://github.com/encse/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/encse/adventofcode.svg)\n* [sanraith/aoc2019](https://github.com/sanraith/aoc2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/sanraith/aoc2019.svg)\n* [sindrekjr/AdventOfCode](https://github.com/sindrekjr/AdventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/sindrekjr/AdventOfCode.svg)\n* [viceroypenguin/adventofcode](https://github.com/viceroypenguin/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/viceroypenguin/adventofcode.svg)\n\n#### C++\n\n*Solutions to AoC in C++.*\n\n* [TheRealMolen/adventofcode2019](https://github.com/TheRealMolen/adventofcode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/TheRealMolen/adventofcode2019.svg)\n* [voivoid/advent-of-code](https://github.com/voivoid/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/voivoid/advent-of-code.svg)\n\n#### Clojure\n\n*Solutions to AoC in Clojure.*\n\n\n* [agrison/advent-of-code-2019](https://github.com/agrison/advent-of-code-2019/) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/agrison/advent-of-code-2019.svg)\n* [alexparlett/advent-of-code-2019](https://github.com/alexparlett/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/alexparlett/advent-of-code-2019.svg)\n* [erdos/advent-of-code-2019](https://github.com/erdos/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/erdos/advent-of-code-2019.svg)\n* [fctorial/adventofcode2019-clojure](https://github.com/fctorial/adventofcode2019-clojure) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/fctorial/adventofcode2019-clojure.svg)\n* [fdlk/advent-2019](https://github.com/fdlk/advent-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/fdlk/advent-2019.svg)\n* [felipecortez/advent-of-code](https://github.com/felipecortez/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/felipecortez/advent-of-code.svg)\n* [jdlambert/advent-of-code-2019](https://github.com/jdlambert/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/jdlambert/advent-of-code-2019.svg)\n* [mastercake10/AdventOfCode2019](https://github.com/mastercake10/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/mastercake10/AdventOfCode2019.svg)\n\n#### Common Lisp\n\n*Solutions to AoC in Common Lisp.*\n\n* [topikettunen/advent-of-code-2019](https://github.com/topikettunen/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/topikettunen/advent-of-code-2019.svg)\n\n#### Crystal\n\n*Solutions to AoC in Crystal.*\n\n* [PenguinOwl/advent2019](https://github.com/PenguinOwl/advent2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/PenguinOwl/advent2019.svg)\n* [salival1/advent-2019](https://github.com/salival1/advent-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/salival1/advent-2019.svg)\n\n#### D\n\n*Solutions to AoC in D.*\n\n* [jrfondren/adventofcode](https://github.com/jrfondren/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/jrfondren/adventofcode.svg)\n* [m3m0ry/2019-advent](https://github.com/m3m0ry/2019-advent) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/m3m0ry/2019-advent.svg)\n\n#### Dart\n\n*Solutions to AoC in Dart.*\n\n* [Awjin/advent-of-code](https://github.com/Awjin/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Awjin/advent-of-code.svg)\n* [julemand101/AdventOfCode2019](https://github.com/julemand101/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/julemand101/AdventOfCode2019.svg)\n\n#### Elixir\n\n*Solutions to AoC in Elixir.*\n\n* [Firebain/adventofcode](https://github.com/Firebain/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Firebain/adventofcode.svg)\n* [dunyakirkali/aoc](https://github.com/dunyakirkali/aoc) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/dunyakirkali/aoc.svg)\n* [es1o/adventofcode](https://github.com/es1o/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/es1o/adventofcode.svg)\n* [jwarwick/aoc_2019](https://github.com/jwarwick/aoc_2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/jwarwick/aoc_2019.svg)\n* [manniL/aoc-2019-elixir](https://github.com/manniL/aoc-2019-elixir) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/manniL/aoc-2019-elixir.svg)\n\n#### Elm\n\n*Solutions to AoC in Elm and Literate Elm.*\n\n#### Erlang\n\n*Solutions to AoC in Erlang.*\n\n* [rhbvkleef/aoc2019](https://github.com/rhbvkleef/aoc2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/rhbvkleef/aoc2019.svg)\n\n#### F#\n\n*Solutions to AoC in F#.*\n\n* [CameronAavik/AdventOfCode](https://github.com/CameronAavik/AdventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/CameronAavik/AdventOfCode.svg)\n* [ChrisPritchard/AdventOfCode](https://github.com/ChrisPritchard/AdventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/ChrisPritchard/AdventOfCode.svg)\n\n#### Go\n\n*Solutions to AoC in Go.*\n\n* [GreenLightning/aoc19](https://github.com/GreenLightning/aoc19) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/GreenLightning/aoc19.svg)\n* [Ullaakut/aoc19](https://github.com/Ullaakut/aoc19) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Ullaakut/aoc19.svg)\n* [chigley/advent2019](https://github.com/chigley/advent2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/chigley/advent2019.svg)\n* [davidaayers/advent-of-code-2019](https://github.com/davidaayers/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/davidaayers/advent-of-code-2019.svg)\n* [devries/advent_of_code_2019](https://github.com/devries/advent_of_code_2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/devries/advent_of_code_2019.svg)\n* [gliderGeek/adventofcode19](https://github.com/gliderGeek/adventofcode19) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/gliderGeek/adventofcode19.svg)\n* [hierynomus/2019-adventofcode.com](https://github.com/hierynomus/code-challenges/tree/master/2019-adventofcode.com) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/hierynomus/code-challenges.svg)\n* [howden/advent19](https://github.com/howden/advent19) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/howden/advent19.svg)\n* [kissgyorgy/adventofcode2019](https://github.com/kissgyorgy/adventofcode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/kissgyorgy/adventofcode2019.svg)\n* [lynerist/Advent-of-code-2019-golang](https://github.com/lynerist/Advent-of-code-2019-golang) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/lynerist/Advent-of-code-2019-golang.svg)\n* [sasom/adventofcode19](https://gitlab.com/sasom/adventofcode19)\n* [thlacroix/goadvent](https://github.com/thlacroix/goadvent) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/thlacroix/goadvent.svg)\n* [williamfhe/advent-of-code-2019](https://github.com/williamfhe/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/williamfhe/advent-of-code-2019.svg)\n* [sevaorlov/adventofcode2019](https://github.com/sevaorlov/adventofcode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/sevaorlov/adventofcode2019.svg)\n\n#### Groovy\n\n*Solutions to AoC in Groovy.*\n\n#### Haskell\n\n*Solutions to AoC in Haskell.*\n\n* [bzuilhof/AdventOfCode](https://github.com/bzuilhof/AdventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/bzuilhof/AdventOfCode.svg)\n* [ephemient/aoc2019#hs](https://github.com/ephemient/aoc2019/tree/hs) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/ephemient/aoc2019/hs.svg)\n* [glguy/advent2019](https://github.com/glguy/advent2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/glguy/advent2019.svg)\n* [hashedone/advent-of-code-2019-hask](https://github.com/hashedone/advent-of-code-2019-hask) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/hashedone/advent-of-code-2019-hask.svg)\n* [nrdmn/adventofcode2019](https://github.com/nrdmn/adventofcode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/nrdmn/adventofcode2019.svg)\n* [webbiscuit/adventofcode](https://github.com/webbiscuit/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/webbiscuit/adventofcode.svg)\n\n#### Idris\n\n*Solutions to AoC in Idris.*\n\n#### Java\n\n*Solutions to AoC in Java.*\n\n* [SimonBaars/adventOfCode-2019](https://github.com/SimonBaars/adventOfCode-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/SimonBaars/adventOfCode-2019.svg)\n* [SizableShrimp/AdventOfCode2019](https://github.com/SizableShrimp/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/SizableShrimp/AdventOfCode2019.svg)\n* [agrison/advent-of-code-2019](https://github.com/agrison/advent-of-code-2019/) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/agrison/advent-of-code-2019.svg)\n* [giganova/advent-of-code-2019-java](https://github.com/giganova/advent-of-code-2019-java) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/giganova/advent-of-code-2019-java.svg)\n\n#### JavaScript\n\n*Solutions to AoC in JavaScript.*\n\n* [GigaNova/advent-of-code-2019](https://github.com/GigaNova/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/GigaNova/advent-of-code-2019.svg)\n* [Jedi-Fullstack-Avengers/AdventOfCode](https://github.com/Jedi-Fullstack-Avengers/AdventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Jedi-Fullstack-Avengers/AdventOfCode.svg)\n* [MaxArt2501/advent-of-code-2019](https://github.com/MaxArt2501/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/MaxArt2501/advent-of-code-2019.svg)\n* [RaedsLab/advent-of-code](https://github.com/RaedsLab/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/RaedsLab/advent-of-code.svg)\n* [arnauddrain/advent-of-code-2019](https://github.com/arnauddrain/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/arnauddrain/advent-of-code-2019.svg)\n* [atme/advent-of-code](https://github.com/atme/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/atme/advent-of-code.svg)\n* [bureson/advent-of-code-2019](https://github.com/bureson/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/bureson/advent-of-code-2019.svg)\n* [chinesedfan/adventofcode](https://github.com/chinesedfan/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/chinesedfan/adventofcode.svg)\n* [countzero/advent_of_code](https://github.com/countzero/advent_of_code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/countzero/advent_of_code.svg)\n* [danieltrost/adventofcode-2019-solutions-js](https://github.com/danieltrost/adventofcode-2019-solutions-js) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/danieltrost/adventofcode-2019-solutions-js.svg)\n* [davidmargolin/Advent-Of-Code-2019](https://github.com/davidmargolin/Advent-Of-Code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/davidmargolin/Advent-Of-Code-2019.svg)\n* [entibo/advent-of-code-golf-2019](https://github.com/entibo/advent-of-code-golf-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/entibo/advent-of-code-golf-2019.svg)\n* [gamma032steam/Advent-of-code](https://github.com/gamma032steam/Advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/gamma032steam/Advent-of-code.svg)\n* [gavinhenderson/advent-of-code](https://github.com/gavinhenderson/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/gavinhenderson/advent-of-code.svg)\n* [imsalahdev/adventofcode-2019](https://github.com/imsalahdev/adventofcode-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/imsalahdev/adventofcode-2019.svg)\n* [jackcutting/aoc2019](https://github.com/jackcutting/aoc2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/jackcutting/aoc2019.svg)\n* [mdelerue/AdventOfCode](https://github.com/mdelerue/AdventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/mdelerue/AdventOfCode.svg)\n* [und3f/advent-of-code-2019](https://github.com/und3f/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/und3f/advent-of-code-2019.svg)\n* [vguerrerobosch/advent-of-code-2019](https://github.com/vguerrerobosch/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/vguerrerobosch/advent-of-code-2019.svg)\n* [vuryss/aoc-2019](https://github.com/vuryss/aoc-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/vuryss/aoc-2019.svg)\n\n#### Julia\n\n*Solutions to AoC in Julia.*\n\n* [gsoleilhac/aoc19.jl](https://github.com/gsoleilhac/aoc19.jl) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/gsoleilhac/aoc19.jl.svg)\n* [kamilbeker/aoc2019.jl](https://github.com/kamilbeker/aoc2019.jl) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/kamilbeker/aoc2019.jl.svg)\n* [racinmat/advent_of_code_2019](https://github.com/racinmat/advent_of_code_2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/racinmat/advent_of_code_2019.svg)\n\n#### Kotlin\n\n*Solutions to AoC in Kotlin.*\n\n* [0legg/adventofcode](https://github.com/0legg/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/0legg/adventofcode.svg)\n* [daafith/advent-of-code-2019](https://github.com/daafith/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/daafith/advent-of-code-2019.svg)\n* [ephemient/aoc2019#kt](https://github.com/ephemient/aoc2019/tree/kt) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/ephemient/aoc2019/kt.svg)\n* [hughjdavey/aoc-2019](https://github.com/hughjdavey/aoc-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/hughjdavey/aoc-2019.svg)\n* [jgoerner/aoc-2019](https://github.com/jgoerner/aoc-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/jgoerner/aoc-2019.svg)\n* [jorispz/aoc-2019](https://github.com/jorispz/aoc-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/jorispz/aoc-2019.svg)\n* [mew/aoc-2019](https://github.com/mew/aoc-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/mew/aoc-2019.svg)\n\n#### LDPL\n\n*Solutions to AoC in LDPL.*\n\n* [Lartu/adventOfCode2019](https://github.com/Lartu/adventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Lartu/adventOfCode2019.svg)\n* [dgarroDC/advent-of-code-2019-ldpl](https://github.com/dgarroDC/advent-of-code-2019-ldpl) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/dgarroDC/advent-of-code-2019-ldpl.svg)\n\n#### Nim\n\n*Solutions to AoC in Nim.*\n\n#### OCaml\n\n*Solutions to AoC in OCaml.*\n\n* [georgek42/AOC2019](https://github.com/georgek42/AOC2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/georgek42/AOC2019.svg)\n\n#### PHP\n\n*Solutions to AoC in PHP.*\n\n* [aran112000/Advent-of-Code-2019-PHP](https://github.com/aran112000/Advent-of-Code-2019-PHP) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/aran112000/Advent-of-Code-2019-PHP.svg)\n* [cbzink/advent-of-code-2019](https://github.com/cbzink/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/cbzink/advent-of-code-2019.svg)\n* [vuryss/aoc-2019](https://github.com/vuryss/aoc-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/vuryss/aoc-2019.svg)\n\n#### Perl\n\n*Solutions to AoC in Perl.*\n\n* [kcaran/adventofcode2019](https://github.com/kcaran/adventofcode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/kcaran/adventofcode2019.svg)\n* [lskatz/advent-of-code](https://github.com/lskatz/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/lskatz/advent-of-code.svg)\n\n#### Pony\n\n*Solutions to AoC in Pony.*\n\n#### PowerShell\n\n*Solutions to AoC in PowerShell.*\n\n* [Crucerio/adventofcode](https://github.com/Crucerio/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Crucerio/adventofcode.svg)\n* [martinkonopka/AdventOfCode2019](https://github.com/martinkonopka/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/martinkonopka/AdventOfCode2019.svg)\n\n#### Python\n\n*Solutions to AoC in Python.*\n\n* [0x8b/advent-of-code-2019](https://github.com/0x8b/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/0x8b/advent-of-code-2019.svg)\n* [Akumatic/Advent-of-Code](https://github.com/Akumatic/Advent-of-Code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Akumatic/Advent-of-Code.svg)\n* [BogDAAAMN/advent-of-code](https://github.com/BogDAAAMN/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/BogDAAAMN/advent-of-code.svg)\n* [Dementophobia/advent-of-code-2019](https://github.com/Dementophobia/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Dementophobia/advent-of-code-2019.svg)\n* [IFinners/advent-of-code](https://github.com/IFinners/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/IFinners/advent-of-code.svg)\n* [JasonCannon/advent-of-code-2019](https://github.com/JasonCannon/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/JasonCannon/advent-of-code-2019.svg)\n* [JesperDramsch/advent-of-code](https://github.com/JesperDramsch/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/JesperDramsch/advent-of-code.svg)\n* [Kurocon/AdventOfCode2019](https://github.com/Kurocon/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Kurocon/AdventOfCode2019.svg)\n* [Levivig/AdventOfCode2019](https://github.com/Levivig/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Levivig/AdventOfCode2019.svg)\n* [Miccowhy/adventofcode2019](https://github.com/Miccowhy/adventofcode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Miccowhy/adventofcode2019.svg)\n* [PatMyron/advent-of-code](https://github.com/PatMyron/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/PatMyron/advent-of-code.svg)\n* [TristoKrempita/advent-of-code](https://github.com/TristoKrempita/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/TristoKrempita/advent-of-code.svg)\n* [a-red-christmas/aoc2019-ae](https://github.com/a-red-christmas/aoc2019-ae) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/a-red-christmas/aoc2019-ae.svg)\n* [elvinyhlee/advent-of-code-2019-python](https://github.com/elvinyhlee/advent-of-code-2019-python) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/elvinyhlee/advent-of-code-2019-python.svg)\n* [ephemient/aoc2019#py](https://github.com/ephemient/aoc2019/tree/py) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/ephemient/aoc2019/py.svg)\n* [gbusch/AdventOfCode](https://github.com/gbusch/AdventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/gbusch/AdventOfCode.svg)\n* [juffalow/advent-of-code](https://github.com/juffalow/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/juffalow/advent-of-code.svg)\n* [mebeim/aoc](https://github.com/mebeim/aoc) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/mebeim/aoc.svg)\n* [metzbernhard/aoc2019](https://github.com/metzbernhard/aoc2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/metzbernhard/aoc2019.svg)\n* [mevdschee/AdventOfCode2019](https://github.com/mevdschee/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/mevdschee/AdventOfCode2019.svg)\n* [mpindaro/advent-of-code-2019](https://bitbucket.org/mpindaro/advent-of-code-2019/src/master/)\n* [polhec42/AOC](https://github.com/polhec42/AOC) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/polhec42/AOC.svg)\n* [r0f1/adventofcode2019](https://github.com/r0f1/adventofcode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/r0f1/adventofcode2019.svg)\n* [ste001/advent-of-code-2019](https://github.com/ste001/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/ste001/advent-of-code-2019.svg)\n* [vincent-vega/adventofcode](https://github.com/vincent-vega/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/vincent-vega/adventofcode.svg)\n* [visini/aoc2019](https://github.com/visini/aoc2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/visini/aoc2019.svg)\n* [zenieldanaku/AdventOfCode](https://github.com/zenieldanaku/AdventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/zenieldanaku/AdventOfCode.svg)\n* [dmies/adventOfCode](https://github.com/dmies/adventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/dmies/adventOfCode.svg)\n\n#### R\n\n*Solutions to AoC in R.*\n\n* [Cattiva/adventofcode](https://github.com/Cattiva/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Cattiva/adventofcode.svg)\n* [EdwinTh/AoC_2019](https://github.com/EdwinTh/AoC_2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/EdwinTh/AoC_2019.svg)\n* [Morawski21/Advent-of-Code-2019-in-R](https://github.com/Morawski21/Advent-of-Code-2019-in-R) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Morawski21/Advent-of-Code-2019-in-R.svg)\n* [adam-gruer/aoc2019](https://github.com/adam-gruer/aoc2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/adam-gruer/aoc2019.svg)\n* [akulumbeg/adventofcode](https://github.com/akulumbeg/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/akulumbeg/adventofcode.svg)\n* [davidmasp/adventofcode-dmp](https://github.com/davidmasp/adventofcode-dmp) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/davidmasp/adventofcode-dmp.svg)\n* [mpjdem/adventofcode2019](https://github.com/mpjdem/adventofcode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/mpjdem/adventofcode2019.svg)\n* [riinuots/advent2019](https://github.com/riinuots/advent2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/riinuots/advent2019.svg)\n\n#### Racket\n\n*Solutions to AoC in Racket.*\n\n* [samdphillips/aoc-2019](https://github.com/samdphillips/aoc-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/samdphillips/aoc-2019.svg)\n\n#### ReasonML\n\n*Solutions to AoC in ReasonML.*\n\n* [believer/advent-of-code](https://github.com/believer/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/believer/advent-of-code.svg)\n\n#### Red\n\n*Solutions to AoC in Red.*\n\n#### Ruby\n\n*Solutions to AoC in Ruby.*\n\n* [Kazhuu/advent-of-code-2019](https://github.com/Kazhuu/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Kazhuu/advent-of-code-2019.svg)\n* [Keirua/adventofcode-rb](https://github.com/Keirua/adventofcode-rb) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Keirua/adventofcode-rb.svg)\n* [Pungsnigel/advent_of_code_2019](https://github.com/Pungsnigel/advent_of_code_2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/Pungsnigel/advent_of_code_2019.svg)\n\n#### Rust\n\n*Solutions to AoC in Rust.*\n\n* [AlexAegis/advent-of-code](https://github.com/AlexAegis/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/AlexAegis/advent-of-code.svg)\n* [AmauryCarrade/AdventOfCode2019](https://github.com/AmauryCarrade/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/AmauryCarrade/AdventOfCode2019.svg)\n* [DarthGandalf/advent-of-code](https://github.com/DarthGandalf/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/DarthGandalf/advent-of-code.svg)\n* [alyti/aoc-2019](https://github.com/alyti/aoc-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/alyti/aoc-2019.svg)\n* [dashed/advent-of-code](https://github.com/dashed/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/dashed/advent-of-code.svg)\n* [fornwall/advent-of-code-2019-rs](https://github.com/fornwall/advent-of-code-2019-rs) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/fornwall/advent-of-code-2019-rs.svg)\n* [hashedone/advent-of-code-2019-rust](https://github.com/hashedone/advent-of-code-2019-rust) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/hashedone/advent-of-code-2019-rust.svg)\n* [jdlambert/advent-of-code-2019](https://github.com/jdlambert/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/jdlambert/advent-of-code-2019.svg)\n* [meyerphi/advent-of-code](https://github.com/meyerphi/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/meyerphi/advent-of-code.svg)\n* [notviri/aoc2019](https://github.com/notviri/aoc2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/notviri/aoc2019.svg)\n* [timvisee/advent-of-code-2019](https://github.com/timvisee/advent-of-code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/timvisee/advent-of-code-2019.svg)\n\n#### Smalltalk\n\n*Solutions to AoC in Smalltalk.*\n\n* [thiagoslino/Advent-of-Code-2019](https://github.com/thiagoslino/Advent-of-Code-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/thiagoslino/Advent-of-Code-2019.svg)\n\n#### Scala\n\n*Solutions to AoC in Scala.*\n\n* [FlorianCassayre/AdventOfCode-2019](https://github.com/FlorianCassayre/AdventOfCode-2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/FlorianCassayre/AdventOfCode-2019.svg)\n* [lupari/aoc](https://github.com/lupari/aoc2019/) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/lupari/aoc2019.svg)\n* [matelaszlo/advent-of-code-scala](https://github.com/matelaszlo/advent-of-code-scala) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/matelaszlo/advent-of-code-scala.svg)\n* [sim642/adventofcode](https://github.com/sim642/adventofcode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/sim642/adventofcode.svg)\n\n#### Scheme\n\n*Solutions to AoC in Scheme.*\n\n* [nenadom/AdventOfCode](https://github.com/nenadom/AdventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/nenadom/AdventOfCode.svg)\n\n#### Swift\n\n*Solutions to AoC in Swift.*\n\n* [davedelong/AOC](https://github.com/davedelong/AOC) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/davedelong/AOC.svg)\n* [evilmint/AdventOfCode](https://github.com/evilmint/AdventOfCode) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/evilmint/AdventOfCode.svg)\n* [fguchelaar/AdventOfCode2019](https://github.com/fguchelaar/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/fguchelaar/AdventOfCode2019.svg)\n* [gernb/AdventOfCode2019](https://github.com/gernb/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/gernb/AdventOfCode2019.svg)\n\n#### TypeScript\n\n*Solutions to AoC in TypeScript.*\n\n* [AlexAegis/advent-of-code](https://github.com/AlexAegis/advent-of-code) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/AlexAegis/advent-of-code.svg)\n* [caderek/aoc2019](https://github.com/caderek/aoc2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/caderek/aoc2019.svg)\n* [florianfreier/AdventOfCode2019](https://github.com/florianfreier/AdventOfCode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/florianfreier/AdventOfCode2019.svg)\n* [izexi/adventofcode2019](https://github.com/izexi/adventofcode2019) ![Last Commit on GitHub](https://img.shields.io/github/last-commit/izexi/adventofcode2019.svg)\n\n#### Zig\n\n*Solutions to AoC in Zig.*\n\n### Live Streams\n\n*Folks who are live streaming their process.*\n"}, {"repo": "BurntSushi/advent-of-code", "language": "Rust", "readme_contents": "BurntSushi's 2018 Advent of Code solutions\n==========================================\n\nI chose to write this year's solutions in Rust. I don't have any particularly\nambitious goals, but I am trying to write the solutions using idiomatic code.\nIn particular, it should not be possible for any input to cause one of the\nsolutions to panic.\n\nI have not spent any time benchmarking the code.\n\nTo run a solution, `cd` into its directory and invoke the program with Cargo:\n\n```\n$ cd aoc01\n$ cargo run --release < input/input.txt\n```\n\nIf you have questions about the code, please open an issue and ask away!\nBeginner questions are very much welcome.\n"}, {"repo": "Lysxia/advent-of-coq-2018", "language": "Coq", "readme_contents": "Advent of Code 2018 in Coq\n==========================\n\nThis repository contains solutions for the Advent of Code 2018\n(https://adventofcode.com/2018). Some of them are formally verified.\nThis is an example of applying verification to small programming\nchallenges of that kind.\n(If you're aiming for prizes, this is probably not the way to go.)\n\nContributions welcome\n---------------------\n\nIt will probably take much longer than the actual span of the AoC to\ncomplete this project, so any help implementing, specifying, or verifying\nsolutions is welcome. If you have any questions, open an issue or send\nme an email (lysxia@gmail.com).\n\n### Suggested tasks\n\n- `day02_2.v`, `day03_2.v` are bare of any verification effort.\n\n- Implement Day 6 (Manhattan geometry).\n\nProject status\n--------------\n\nAs of December 2, the two solutions of Day 1's challenge are\nverified (significant caveats apply).\n\nRead more about my approach in [`SUMMARY.md`](./SUMMARY.md).\n\nDependencies\n------------\n\n- [coq-simple-io](https://github.com/Lysxia/coq-simple-io), master\n\n    This project serves to test coq-simple-io and see what is missing to\n    make it practical to write executable programs in Coq.\n\n- [coq-ext-lib](https://github.com/coq-ext-lib/coq-ext-lib), 0.10\n\n- [Coq](https://coq.inria.fr/), 8.8.2\n\n- [OCaml](https://ocaml.org), 4.07.0\n\nOlder versions of these are likely to work.\n\n### Optional dependency\n\n- [coq-itree](https://github.com/DeepSpec/InteractionTrees), master.\n  A library of free monads and algebraic effects (WIP).\n\nExperimental proofs using `itree` instead of `io_rel` can be found in\nfiles `sol/day*_*_extra.v`.\n\nTo install coq-itree with opam and make it known to advent-of-coq:\n\n```sh\ngit clone https://github.com/DeepSpec/InteractionTrees\nopam pin add coq-itree ./InteractionTrees\n\n# Inside advent-of-coq-2018, create a symbolic link _CoqConfig.append\n# to _CoqConfig.extras\n# The -f option overwrites any existing _CoqConfig.append\nln -sf _CoqConfig.extras _CoqConfig.append\n\n# (Re)generate _CoqProject and compile lib.itree\nmake lib\n```\n\nInstall the development version of coq-simple-io with opam\n----------------------------------------------------------\n\n```sh\n# Get the source\ngit clone https://github.com/Lysxia/coq-simple-io\n\n# Register the local version of coq-simple-io with opam\nopam pin add -k git coq-simple-io ./coq-simple-io\n\n# When coq-simple-io is updated\ncd coq-simple-io && git pull coq-simple-io\nopam reinstall coq-simple-io\n```\n\nBuild\n-----\n\nTo compile and run `day01_1.v` for example:\n\n```sh\nmake exe/day01_1\n./exe/day01_1 < txt/day01\n```\n"}, {"repo": "fogleman/AdventOfCode2018", "language": "Python", "readme_contents": "# Advent of Code 2018\n\nMy solutions to the Advent of Code 2018 problems.\n\nCheck out the blog post, which explains how the solutions work and includes more comments in the code:\n\nhttps://www.michaelfogleman.com/aoc18/\n\nRun the solutions like so:\n\n    $ python 1.py 1.txt\n"}, {"repo": "mstksg/advent-of-code-2018", "language": "Haskell", "readme_contents": "Advent of Code 2018\n===================\n\n*[2016][]* / *[2017][]* / *2018* / *[2019][]*\n\n[2016]: https://github.com/mstksg/advent-of-code-2016\n[2017]: https://github.com/mstksg/advent-of-code-2017\n[2019]: https://github.com/mstksg/advent-of-code-2019\n\nIt's the most wonderful time of the year!\n\nMy [Advent of Code 2018][aoc2018] Haskell solutions here, along with an automated\nfetching, testing, running environment (powered by the\n*[advent-of-code-api][]* library).  The interactive development environment and\nrunner/bench marker/viewer/tester has been pulled out [here][dev], so this is\nimplemented as \"fork\" of it with my own solutions and reflections.\n\nCheck out reflections and commentary at the [package haddocks][haddock]!\n(individual links down below)\n\n[aoc2018]: https://adventofcode.com/2018\n[haddock]: https://mstksg.github.io/advent-of-code-2018/\n[advent-of-code-api]: https://hackage.haskell.org/package/advent-of-code-api\n[dev]: https://github.com/mstksg/advent-of-code-dev\n\n[Reflections and Benchmarks][reflections]\n-----------------------------------------\n\n*   **[Day 1 Reflections][d01r]** *[code][d01g]* / *[rendered][d01h]* / *[benchmarks][d01b]*\n*   **[Day 2 Reflections][d02r]** *[code][d02g]* / *[rendered][d02h]* / *[benchmarks][d02b]*\n*   **[Day 3 Reflections][d03r]** *[code][d03g]* / *[rendered][d03h]* / *[benchmarks][d03b]*\n*   **[Day 4 Reflections][d04r]** *[code][d04g]* / *[rendered][d04h]* / *[benchmarks][d04b]*\n*   **[Day 5 Reflections][d05r]** *[code][d05g]* / *[rendered][d05h]* / *[benchmarks][d05b]*\n*   **[Day 6 Reflections][d06r]** *[code][d06g]* / *[rendered][d06h]* / *[benchmarks][d06b]*\n*   **[Day 7 Reflections][d07r]** *[code][d07g]* / *[rendered][d07h]* / *[benchmarks][d07b]*\n*   **[Day 8 Reflections][d08r]** *[code][d08g]* / *[rendered][d08h]* / *[benchmarks][d08b]*\n*   **[Day 9 Reflections][d09r]** *[code][d09g]* / *[rendered][d09h]* / *[benchmarks][d09b]*\n*   **[Day 10 Reflections][d10r]** *[code][d10g]* / *[rendered][d10h]* / *[benchmarks][d10b]*\n*   **[Day 11 Reflections][d11r]** *[code][d11g]* / *[rendered][d11h]* / *[benchmarks][d11b]*\n*   **[Day 12 Reflections][d12r]** *[code][d12g]* / *[rendered][d12h]* / *[benchmarks][d12b]*\n*   **[Day 13 Reflections][d13r]** *[code][d13g]* / *[rendered][d13h]* / *[benchmarks][d13b]*\n*   **[Day 14 Reflections][d14r]** *[code][d14g]* / *[rendered][d14h]*\n*   **Day 15 Reflections** *[code][d15g]* / *[rendered][d15h]*\n*   **[Day 16 Reflections][d16r]** *[code][d16g]* / *[rendered][d16h]* / *[benchmarks][d16b]*\n*   **Day 17 Reflections** *[code][d17g]* / *[rendered][d17h]*\n*   **Day 18 Reflections** *[code][d18g]* / *[rendered][d18h]*\n*   **Day 19 Reflections** *[code][d19g]* / *[rendered][d19h]*\n*   **[Day 20 Reflections][d20r]** *[code][d20g]* / *[rendered][d20h]* / *[benchmarks][d20b]*\n*   **Day 21 Reflections** *[code][d21g]* / *[rendered][d21h]*\n*   **Day 22 Reflections** *[code][d22g]* / *[rendered][d22h]*\n*   **Day 23 Reflections** *[code][d23g]* / *[rendered][d23h]*\n*   **Day 24 Reflections** *[code][d24g]* / *[rendered][d24h]*\n\n\"Rendered\" links go to haddock source renders for code, with reflections in the\ndocumentation.  Haddock source renders have hyperlinked identifiers,\nso you can follow any unrecognized identifiers to see where I have defined them\nin the library.\n\n[reflections]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md\n\n### `:~>` type\n\nIf you're looking at my actual github solutions, you'll notice thattThis year\nI'm implementing my solutions in terms of a `:~>` record type:\n\n```haskell\ndata a :~> b = MkSol\n    { sParse :: String -> Maybe a    -- ^ parse input into an `a`\n    , sSolve :: a      -> Maybe b    -- ^ solve an `a` input to a `b` solution\n    , sShow  :: b      -> String     -- ^ print out the `b` solution for submission\n    }\n```\n\nAn `a :~> b` is a solution to a challenge expecting input of type `a` and\nproducing answers of type `b`.  It also packs in functions to parse a `String`\ninto an `a`, and functions to show a `b` as a `String` to submit as an answer.\n\nThis helps me mentally separate out parsing, solving, and showing, allowing for\nsome cleaner code and an easier time planning my solution.\n\nSuch a challenge can be \"run\" on string inputs by feeding the string into\n`sParse`, then `sSolve`, then `sShow`:\n\n```haskell\n-- | Run a ':~>' on some input, retuning 'Maybe'\nrunSolution :: Challenge -> String -> Maybe String\nrunSolution MkSol{..} s = do\n    x <- sParse s\n    y <- sSolve x\n    pure $ sShow y\n```\n\nIn the actual library, I have `runSolution` return an `Either` so I can debug\nwhich stage the error happened in.\n\nYou might also notice the function `dyno_`, used like `dyno_ \"limit\" 10000`.  This\nis how I implement parameters in problems that vary between test data and\nactual input.  For example, Day 6 involved finding points that had a total\ndistance of less than 10000, but for the test input, we found the points that\nhad a total distance of less than 32.  So, I have a system that lets me write\n`dyno_ \"limit\" 10000` in my code instead of hard-coding in `10000`.  This\n`10000` would be replaced by `32` when running with test data (which is parsed\nfrom [this file][7btest])\n\n[7btest]: https://github.com/mstksg/advent-of-code-2018/blob/master/test-data/06b.txt\n\nInteractive\n-----------\n\nThe *[AOC2018.Run.Interactive][interactive]* module has code (powered by\n*[advent-of-code-api][]*) for testing your solutions and submitting within\nGHCI, so you don't have to re-compile. If you edit your solution programs, they\nare automatically updated when you hit `:r` in ghci.\n\n[interactive]: https://mstksg.github.io/advent-of-code-2018/AOC2018-Run-Interactive.html\n\n```haskell\nghci> execSolution_   $ mkCS 2 'a'  -- get answer for challenge based on solution\nghci> testSolution_   $ mkCS 2 'a'  -- run solution against test suite\nghci> viewPrompt_     $ mkCS 2 'a'  -- view the prompt for a part\nghci> waitForPrompt_  $ mkCS 2 'a'  -- count down to the prompt for a part\nghci> submitSolution_ $ mkCS 2 'a'  -- submit a solution\n```\n\nThese are loaded with session key stored in the configuration file (see next\nsection).\n\nExecutable\n----------\n\nComes with test examples given in problems.\n\nYou can install using `stack`:\n\n```bash\n$ git clone https://github.com/mstksg/advent-of-code-2018\n$ cd advent-of-code-2018\n$ stack setup\n$ stack install\n```\n\nThe executable `aoc2018` includes a testing and benchmark suite, as well as a\nway to view prompts within the command line:\n\n```\n$ aoc2018 --help\naoc2018 - Advent of Code 2018 challenge runner\n\nUsage: aoc2018 [-c|--config PATH] COMMAND\n  Run challenges from Advent of Code 2018. Available days: 1, 2, 3 (..)\n\nAvailable options:\n  -c,--config PATH         Path to configuration file (default: aoc-conf.yaml)\n  -h,--help                Show this help text\n\nAvailable commands:\n  run                      Run, test, and benchmark challenges\n  view                     View a prompt for a given challenge\n  submit                   Test and submit answers for challenges\n  test                     Alias for run --test\n  bench                    Alias for run --bench\n  countdown                Alias for view --countdown\n\n$ aoc2018 run 3 b\n>> Day 03b\n>> [\u2713] 243\n```\n\nYou can supply input via stdin with `--stdin`:\n\n```\n$ aoc2018 run 1 --stdin\n>> Day 01a\n+1\n+2\n+1\n-3\n<Ctrl+D>\n[?] 1\n>> Day 01b\n[?] 1\n```\n\nBenchmarking is implemented using *criterion*\n\n```\n$ aoc2018 bench 2\n>> Day 02a\nbenchmarking...\ntime                 1.317 ms   (1.271 ms .. 1.392 ms)\n                     0.982 R\u00b2   (0.966 R\u00b2 .. 0.999 R\u00b2)\nmean                 1.324 ms   (1.298 ms .. 1.373 ms)\nstd dev              115.5 \u03bcs   (77.34 \u03bcs .. 189.0 \u03bcs)\nvariance introduced by outliers: 65% (severely inflated)\n\n>> Day 02b\nbenchmarking...\ntime                 69.61 ms   (68.29 ms .. 72.09 ms)\n                     0.998 R\u00b2   (0.996 R\u00b2 .. 1.000 R\u00b2)\nmean                 69.08 ms   (68.47 ms .. 69.99 ms)\nstd dev              1.327 ms   (840.8 \u03bcs .. 1.835 ms)\n```\n\nTest suites run the example problems given in the puzzle description, and\noutputs are colorized in ANSI terminals.\n\n```\n$ aoc2018 test 1\n>> Day 01a\n[\u2713] (3)\n[\u2713] (3)\n[\u2713] (0)\n[\u2713] (-6)\n[\u2713] Passed 4 out of 4 test(s)\n[\u2713] 416\n>> Day 01b\n[\u2713] (2)\n[\u2713] (0)\n[\u2713] (10)\n[\u2713] (5)\n[\u2713] (14)\n[\u2713] Passed 5 out of 5 test(s)\n[\u2713] 56752\n```\n\nThis should only work if you're running `aoc2018` in the project directory.\n\n**To run on actual inputs**, the executable expects inputs to be found in the\nfolder `data/XX.txt` in the directory you are running in.  That is, the input\nfor Day 7 will be expected at `data/07.txt`.\n\n*aoc2018 will download missing input files*, but requires a session token.\nThis can be provided in `aoc-conf.yaml`:\n\n```yaml\nsession:  [[ session token goes here ]]\n```\n\nSession keys are also required to download \"Part 2\" prompts for each challenge.\n\nYou can \"lock in\" your current answers (telling the executable that those are\nthe correct answers) by passing in `--lock`.  This will lock in any final\npuzzle solutions encountered as the verified official answers.  Later, if you\nedit or modify your solutions, they will be checked on the locked-in answers.\n\nThese are stored in `data/ans/XXpart.txt`.  That is, the target output for Day 7\n(Part 2, `b`) will be expected at `data/ans/07b.txt`.  You can also manually\nedit these files.\n\nYou can view prompts: (use `--countdown` to count down until a prompt is\nreleased, and display immediately)\n\n```\n$ aoc2018 view 3 b\n>> Day 03b\n--- Part Two ---\n----------------\n\nAmidst the chaos, you notice that exactly one claim doesn't overlap by\neven a single square inch of fabric with any other claim. If you can\nsomehow draw attention to it, maybe the Elves will be able to make\nSanta's suit after all!\n\nFor example, in the claims above, only claim `3` is intact after all\nclaims are made.\n\n*What is the ID of the only claim that doesn't overlap?*\n```\n\nYou can also submit answers:\n\n```\n$ aoc2018 submit 1 a\n```\n\nSubmissions will automatically run the test suite.  If any tests fail, you will\nbe asked to confirm submission or else abort.  The submit command will output\nthe result of your submission: The message from the AoC website, and whether or\nnot your answer was correct (or invalid or ignored).  Answers that are\nconfirmed correct will be locked in and saved for future testing against, in\ncase you change your solution.\n\nAll networking features are powered by *[advent-of-code-api][]*.\n\n[d01g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day01.hs\n[d01h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day01.html\n[d01r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-1\n[d01b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-1-benchmarks\n\n[d02g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day02.hs\n[d02h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day02.html\n[d02r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-2\n[d02b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-2-benchmarks\n\n[d03g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day03.hs\n[d03h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day03.html\n[d03r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-3\n[d03b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-3-benchmarks\n\n[d04g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day04.hs\n[d04h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day04.html\n[d04r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-4\n[d04b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-4-benchmarks\n\n[d05g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day05.hs\n[d05h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day05.html\n[d05r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-5\n[d05b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-5-benchmarks\n\n[d06g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day06.hs\n[d06h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day06.html\n[d06r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-6\n[d06b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-6-benchmarks\n\n[d07g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day07.hs\n[d07h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day07.html\n[d07r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-7\n[d07b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-7-benchmarks\n\n[d08g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day08.hs\n[d08h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day08.html\n[d08r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-8\n[d08b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-8-benchmarks\n\n[d09g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day09.hs\n[d09h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day09.html\n[d09r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-9\n[d09b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-9-benchmarks\n\n[d10g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day10.hs\n[d10h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day10.html\n[d10r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-10\n[d10b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-10-benchmarks\n\n[d11g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day11.hs\n[d11h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day11.html\n[d11r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-11\n[d11b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-11-benchmarks\n\n[d12g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day12.hs\n[d12h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day12.html\n[d12r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-12\n[d12b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-12-benchmarks\n\n[d13g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day13.hs\n[d13h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day13.html\n[d13r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-13\n[d13b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-13-benchmarks\n\n[d14g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day14.hs\n[d14h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day14.html\n[d14r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-14\n\n[d15g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day15.hs\n[d15h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day15.html\n\n[d16g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day16.hs\n[d16h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day16.html\n[d16r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-16\n[d16b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-16-benchmarks\n\n[d17g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day17.hs\n[d17h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day17.html\n\n[d18g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day18.hs\n[d18h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day18.html\n\n[d19g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day19.hs\n[d19h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day19.html\n\n[d20g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day20.hs\n[d20h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day20.html\n[d20r]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-20\n[d20b]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md#day-20-benchmarks\n\n[d21g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day21.hs\n[d21h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day21.html\n\n[d22g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day22.hs\n[d22h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day22.html\n\n[d23g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day23.hs\n[d23h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day23.html\n\n[d24g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day24.hs\n[d24h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day24.html\n"}, {"repo": "Voltara/advent2018-fast", "language": "C++", "readme_contents": "# advent2018-fast\n\n[Advent of Code 2018](http://adventofcode.com/2018/) optimized C++ solutions.\n\nHere are the timings from an example run on an i7-7700K CPU overclocked at 4.60 GHz.  The total is greater than the sum of the individual days because of rounding.\n\n    Day  1       72 \u03bcs\n    Day  2       27 \u03bcs\n    Day  3      205 \u03bcs\n    Day  4       82 \u03bcs\n    Day  5      414 \u03bcs\n    Day  6    1,346 \u03bcs\n    Day  7        3 \u03bcs\n    Day  8       62 \u03bcs\n    Day  9    4,385 \u03bcs\n    Day 10       21 \u03bcs\n    Day 11      485 \u03bcs\n    Day 12       61 \u03bcs\n    Day 13      642 \u03bcs\n    Day 14   19,067 \u03bcs\n    Day 15    2,132 \u03bcs\n    Day 16       80 \u03bcs\n    Day 17      544 \u03bcs\n    Day 18      307 \u03bcs\n    Day 19        2 \u03bcs\n    Day 20       92 \u03bcs\n    Day 21      101 \u03bcs\n    Day 22    3,546 \u03bcs\n    Day 23      383 \u03bcs\n    Day 24    6,711 \u03bcs\n    Day 25      177 \u03bcs\n    ------------------\n    Total    40,959 \u03bcs\n\nSolutions should work with any puzzle input, provided it is byte-for-byte an exact copy of the file downloaded from Advent of Code.  When an input is given as a number inline with the puzzle text (days 11 and 14), the input file should contain only the number itself followed by a single line feed character (ASCII 12).\n\nThis code makes extensive use of SIMD techniques and requires a CPU that supports the AVX2 instruction set.\n\n# Summary of solutions\n\nHere are a few brief notes about each solution.\n\n## Day 1\n\nSee [this post](https://www.reddit.com/r/adventofcode/comments/a20646/2018_day_1_solutions/eaukxu5) on the subreddit.\n\n## Day 2\n\nEach 26-character word fits in a 32-byte AVX2 register, which allows for very fast comparisons.  Exploits regularities in the input to eliminate many candidate words from consideration.\n\n## Day 3\n\nRepresents a row of fabric as a 1024-bit mask (16 64-bit integers.)  Scans the fabric vertically one row at a time using a sweep-line algorithm, considering only those claims which intersect the current row, 20-25 claims on average.\n\n## Day 4\n\nSIMD solution that stores the 60 minutes of the hour in two 32x8 bit AVX2 vectors.\n\n## Day 5\n\nStraightforward stack-based solution.  Tried various ways to prune the Part 2 search, but the added bookkeeping outweighed the time saved.\n\n## Day 6\n\nPart 1 is a basic flood fill; part 2 is a sweep-line algorithm that traces the outline of the \"safe\" region.\n\n## Day 7\n\nA SIMD take on topological sorting.  The letters A-Z fit nicely within a 32x8 AVX2 vector.\n\n## Day 8\n\nStraightforward recursive solution.\n\n## Day 9\n\nA shuffle/permute heavy SIMD implementation of the marble game's rules, in 23-turn increments.  Only needs to fully simulate ~43% of the game; the score for the remainder of the game can be found by tallying up every 16th marble in the array.\n\n## Day 10\n\nCalculates Part 2 based on the fastest-moving particles in the y-direction.  The final position of each star is added to a bitmap of eight 64-bit integers (each letter is 6x10.)  The resulting values are converted to letters by hashtable lookup.\n\n## Day 11\n\nBuilds an integral image (summed area table) of the 300x300 area, and does so in a way that the compiler can vectorize.  Searching for the solutions is done via explicit SIMD.  Stops the search at \"6 sigmas\" of confidence.\n\n## Day 12\n\nLive/dead cells are stored as a bool vector, which C++ implements as a bitset.  Comparing the previous and current states is very fast; my input stabilizes at a vector length of 190, which is only 3 64-bit integers.  The rules are stored as a single 32-bit integer, and are evaluated by iterating over the current state with a 5-bit rolling window, which is used to index individual bits in the rules integer.\n\n## Day 13\n\nFairly straightforward simulation of the minecarts.\n\n## Day 14\n\nThis was the hardest puzzle to optimize.  The irregular write pattern limits the ability to vectorize the loop.  See [this post](https://www.reddit.com/r/adventofcode/comments/a6wpwa/2018_day_14_breaking_the_1_billion_recipes_per/) for a detailed description.\n\n## Day 15\n\nThe 32x32 map fits in four 256-bit AVX2 registers when treated as a bitmap.  This makes for quick pathfinding by bitwise flood fill.  The map is split into three 1024-bit overlays: open space, elves, and goblins.\n\n## Day 16\n\nMostly straightforward, using bit fields to keep track of which opcodes are valid for which instructions.\n\n## Day 17\n\nRecursively traces where the water flows.  I didn't spend much time trying to optimizing this; it is mostly just a copy/paste from my original solution repository.\n\n## Day 18\n\nA SIMD bonanza, even when \"parsing\" the input (which just does a SIMD bitwise AND with `0x11` on 32 input characters at a time to produce `0x00` for open space, `0x10` for trees, and `0x01` for lumberyards.)  This is actually a SIMD/SWAR hybrid, because the trees and lumberyards each occupy 4-bit fields within each 8-bit field of the 32-byte AVX2 register.\n\n## Day 19\n\nExecutes instructions until it reaches the main loop.  Uses wheel factorization to find the prime factors, which are used to compute the divisor sum.\n\n## Day 20\n\nExploits how the input was generated to solve both parts using a small stack of coordinate/distance and an even smaller cache of recently visited coordinates.\n\n## Day 21\n\nReads only one number from the input (the only one that matters), and uses it as input to an optimized SIMD version of the generator.  Uses Brent's cycle-detection algorithm to solve Part 2.\n\n## Day 22\n\nVery minimalistic A\\* using a 17-bucket priority queue.  Tool switching is done by bitwise arithmetic between tool and terrain.\n\n## Day 23\n\nSee [this discussion](https://www.reddit.com/r/adventofcode/comments/a9co1u/day_23_part_2_adversarial_input_for_recursive/ecmpxad) on the subreddit.\n\n## Day 24\n\nPredetermines which groups are valid targets of each other, keeping a separate list of targets that are weak to the attack type.  These lists are stored as bitmasks.  Avoids sorting the array of attackers each round; instead, when a group is damaged, it bubbles down the target-selection list (they rarely move more than 1-2 slots at a time, if any.)  Otherwise, this is just a straight simulation of the battles.\n\n## Day 25\n\nUnion-find algorithm, in cooperation with SIMD pairwise comparisons between each of the points.\n"}, {"repo": "wimglenn/advent-of-code-data", "language": "Python", "readme_contents": "Advent of Code data\n===================\n\n|pyversions|_ |pypi|_ |womm|_ |travis|_ |coveralls|_\n\n.. |pyversions| image:: https://img.shields.io/pypi/pyversions/advent-of-code-data.svg\n.. _pyversions: \n\n.. |pypi| image:: https://img.shields.io/pypi/v/advent-of-code-data.svg\n.. _pypi: https://pypi.org/project/advent-of-code-data/\n\n.. |womm| image:: https://cdn.rawgit.com/nikku/works-on-my-machine/v0.2.0/badge.svg\n.. _womm: https://github.com/nikku/works-on-my-machine\n\n.. |travis| image:: https://img.shields.io/travis/wimglenn/advent-of-code-data.svg?branch=master\n.. _travis: https://travis-ci.com/wimglenn/advent-of-code-data\n\n.. |coveralls| image:: https://coveralls.io/repos/github/wimglenn/advent-of-code-data/badge.svg?branch=master\n.. _coveralls: https://coveralls.io/github/wimglenn/advent-of-code-data?branch=master\n\n\nGet your puzzle data with a single import statement:\n\n.. code-block:: python\n\n   from aocd import data\n\nMight be useful for lazy Pythonistas and speedhackers.  \n\n**Note:  Please use version 0.3+ of this library.**  It memoizes successful\nrequests client side and rate-limits the get_data function, as\n`requested by the AoC author <https://www.reddit.com/r/adventofcode/comments/3v64sb/aoc_is_fragile_please_be_gentle/>`_.\nThanks!\n\n\nQuickstart\n----------\n\nInstall with pip\n\n.. code-block:: bash\n\n   pip install advent-of-code-data\n\n**Puzzle inputs differ by user.**   So export your session ID, for example:\n\n.. code-block:: bash\n\n   export AOC_SESSION=cafef00db01dfaceba5eba11deadbeef\n\nThis is a cookie which is set when you login to AoC.  You can find it with\nyour browser inspector.  If you're hacking on AoC at all you probably already\nknow these kind of tricks, but if you need help with that part then you can\n`look here <https://github.com/wimglenn/advent-of-code/issues/1>`_.\n\n*Note:* If you don't like the env var, you could also put into a text file\nin your home directory (use the filename ``~/.config/aocd/token``).\n\n\nAutomated submission\n--------------------\n\n*New in version 0.4.0.* Basic use:\n\n.. code-block:: python\n\n   from aocd import submit\n   submit(my_answer, part=\"a\", day=25, year=2017)\n\nNote that the same filename introspection of year/day also works for automated\nsubmission. There's also introspection of the \"level\", i.e. part a or part b,\naocd can automatically determine if you have already completed part a or not\nand submit your answer for the correct part accordingly. In this case, just use:\n\n.. code-block:: python\n\n   from aocd import submit\n   submit(my_answer)\n\nThe response message from AoC will be printed in the terminal. If you gave\nthe right answer, then the puzzle will be refreshed in your web browser\n(so you can read the instructions for the next part, for example).\n**Proceed with caution!** If you submit wrong guesses, your user **WILL**\nget rate-limited by Eric, so don't call submit until you're fairly confident\nyou have a correct answer!\n\n\nOOP-style interfaces\n--------------------\n\n*New in version 0.8.0.*\n\nInput data is via regular attribute access. Example usage:\n\n.. code-block:: python\n\n    >>> from aocd.models import Puzzle\n    >>> puzzle = Puzzle(year=2017, day=20)\n    >>> puzzle\n    <Puzzle(2017, 20) at 0x107322978 - Particle Swarm>\n    >>> puzzle.input_data\n    'p=<-1027,-979,-188>, v=<7,60,66>, a=<9,1,-7>\\np=<-1846,-1539,-1147>, v=<88,145,67>, a=<6,-5,2> ...\n\nSubmitting answers is also by regular attribute access. Any incorrect answers you submitted are remembered, and aocd will prevent you from attempting to submit the same incorrect value twice:\n\n.. code-block:: python\n\n    >>> puzzle.answer_a = 299\n    That's not the right answer; your answer is too high. If you're stuck, there are some general tips on the about page, or you can ask for hints on the subreddit. Please wait one minute before trying again. (You guessed 299.) [Return to Day 20]\n    >>> puzzle.answer_a = 299\n    aocd will not submit that answer again. You've previously guessed 299 and the server responded:\n    That's not the right answer; your answer is too high. If you're stuck, there are some general tips on the about page, or you can ask for hints on the subreddit. Please wait one minute before trying again. (You guessed 299.) [Return to Day 20]\n\nSolutions can be executed using `setuptools style plugins <https://setuptools.readthedocs.io/en/latest/setuptools.html#dynamic-discovery-of-services-and-plugins>`_ for your code, i.e. the ``pkg_resources`` \"entry-points\". My entry-point name is \"wim\" so an example for running `my code <https://github.com/wimglenn/advent-of-code-wim/blob/master/setup.py#L30>`_ (after ``pip install advent-of-code-wim``) would be:\n\n.. code-block:: python\n\n    >>> puzzle = Puzzle(year=2018, day=10)\n    >>> puzzle.solve_for(\"wim\")\n    ('XLZAKBGZ', '10656')\n\n\nVerify your code against multiple different inputs\n--------------------------------------------------\n\n*New in version 0.8.0.*\n\nEver tried running your code against other people's inputs? AoC is full of tricky edge cases. You may find that sometimes you're only getting the right answer by luck, and your code will fail on some other dataset. Using aocd, you can collect a few different auth tokens for each of your accounts (github/google/reddit/twitter) and verify your answers across multiple datasets.\n\nTo see an example of how to setup the entry-point for your code, look at `advent-of-code-sample <https://github.com/wimglenn/advent-of-code-sample>`_ for some inspiration. After dumping a bunch of session tokens into ``~/.config/aocd/tokens.json`` you could do something like this by running the ``aoc`` console script:\n\n.. image:: https://user-images.githubusercontent.com/6615374/52138567-26e09f80-2613-11e9-8eaf-c42757bc9b86.png\n\nAs you can see above, I actually had incorrect code for `2017 Day 20: Particle Swarm <https://adventofcode.com/2017/day/20>`_, but that `bug <https://github.com/wimglenn/advent-of-code-wim/commit/31e454270001c6d06b46014fe5dafd03e29507b8>`_ only showed up for the google token's dataset. Whoops. Also, it looks like my algorithm for `2017 Day 13: Packet Scanners <https://adventofcode.com/2017/day/13>`_ was kinda garbage. Too slow. According to `AoC FAQ <https://adventofcode.com/about>`_:\n\n  *every problem has a solution that completes in at most 15 seconds on ten-year-old hardware*\n\nBy the way, the ``aoc`` runner will kill your code if it takes more than 60 seconds, you can increase/decrease this by passing a command-line option, e.g. ``--timeout=120``.\n\n\nHow does this library work?\n---------------------------\n\nIt will automatically get today's data at import time, if used within the \ninteractive interpreter.  Otherwise, the date is found by introspection of the\npath and file name from which ``aocd`` module was imported.  \n\nThis means your filenames should be something sensible. The examples below\nshould all parse correctly, because they have digits in the path that are\nunambiguously recognisable as AoC years (2015+) or days (1-25).\n\n.. code-block::\n\n   q03.py \n   xmas_problem_2016_25b_dawg.py\n   ~/src/aoc/2015/p8.py\n\nA filename like ``problem_one.py`` will not work, so don't do that.  If\nyou don't like weird frame hacks, just use the ``aocd.get_data()`` function \ninstead and have a nice day!\n\n.. code-block:: python\n\n   >>> from aocd import get_data\n   >>> get_data(day=2)\n   'UULDRRRDDLRLURUUURUURDRUURRDRRURUD...\n   >>> get_data(day=24, year=2015)\n   '1\\n2\\n3\\n7\\n11\\n13\\n17\\n19\\n23\\n31...\n\n\nCache invalidation?\n-------------------\n\n``aocd`` saves puzzle inputs, answers, names, and your bad guesses to avoid hitting\nthe AoC servers any more often than strictly necessary (this also speeds things up).\nAll data is persisted in plain text files under ``~/.config/aocd``. To remove any\ncaches, you may simply delete whatever files you want under that directory tree.\nIf you'd prefer to use a different path, then export an ``AOCD_DIR`` environment\nvariable with the desired location.\n"}, {"repo": "ChrisPenner/Advent-Of-Code-Polyglot", "language": "Python", "readme_contents": "Advent of Code\n==============\n\nThis is a collection of [Advent of Code](http://adventofcode.com/) solutions in\nmany different programming languages.\n\nFor the uninitiated, [Advent of Code](http://adventofcode.com/) is a series of\nprogramming challenges, a new one is released each day until Dec. 25th.\n\nEach challenge requires thinking in a different way to solve it, and for this\nreason it provides an interesting look at how programming languages approach\neach problem.\n\nYou'll notice that in any given situation, the idiomatic Python way of solving\nsomething will be very different from the Haskell or Lisp way of doing things.\n\nGuidelines\n----------\n\n-   Create a Pull Request for any contributions.\n-   Feel free to put your name or website in a comment at the top of your\n    solution if you like.\n-   I won't merge any solutions until a few days after each problem is released\n    to allow the dust to settle, don't rush in making your PR's, it's not first\n    come first merged.\n-   The goal of the project is to see the most idiomatic way to solve each\n    problem in a given language, for this reason I will keep only the solution\n    which I feel best encapsulates 'idiomatic' code of that language. (Or will\n    defer to the community in cases where it is unclear)\n-   Please don't include your problem's 'input.txt' or solution, as these are\n    different for each person.\n-   Please put each solution (part 1 and part 2) into separate files (even if\n    there's a bit of code duplication) it makes it easier to figure out what's\n    going on.\n-   Solutions should be easy to read (even for people who don't know the\n    programming language), so include comments explaining your solution and any\n    interesting\n-   programming language tricks/idioms you're using.\n-   In pull requests please follow the established pattern:\n-   `year/language-name/day-num/part#.extension`\n\nDon't get too competitive about it, someone else's solution may be accepted instead\nof yours, keep working at it and try to be as elegant and idiomatic as possible!\n\nRemember to have fun!!\n"}, {"repo": "jaksi/advent-of-other-peoples-code", "language": "Python", "readme_contents": "# Advent of Other People's Code\nFetches random solutions to a specified [Advent of Code](https://adventofcode.com/) puzzle from GitHub and runs them against your input\n![Grinch](grinch.png)\n## Usage\nLet me rephrase. This is going to get some random code from GitHub and run it on your machine. Don't use it.\n\n## Really tho\n### Create a virtualenv\n```sh\npython3 -m venv env\nsource env/bin/activate\n```\n\n### Install requirements\n```sh\npip install -r requirements.txt\n```\n\n### Genrate a GitHub personal access token\n[Right here](https://github.com/settings/tokens/new), with the `public_repo` scope.\n\n### Run it\nPlease, don't!\n\n### I said run it!\n```shellsession\n$ python advent.py --token $GITHUB_TOKEN --year 2018 --day 3 --input input.txt\nPatching open() to always return your input file\nSearching for repositories\nSearching for a solution in Karlovsky120/AdventOfCode2018\nSearching for a solution in grey-area/advent-of-code-2018\nSearching for a solution in stefsiekman/aoc2018\nSearching for a solution in BenSchomp/adventofcode2018\nSearching for a solution in speedyswimmer1000/AoC2018\nAbout to blindly run https://github.com/speedyswimmer1000/AoC2018/blob/master/day3.py.\nType yes if you think that's a good idea.\nHint: it's not.\nyes\nRunning it, stand back.\nIt raised an exception.\nSearching for a solution in zinh/advent-of-code-2018\nSearching for a solution in aaralh/AdventOfCode\nSearching for a solution in athas/advent_of_code_2018\nSearching for a solution in hawkjo/advent_of_code_2018\nSearching for a solution in Landmaj/AoC_2018\nSearching for a solution in paiv/aoc2018\nSearching for a solution in helenacruz/adventofcode2018\nSearching for a solution in StevTheDev/AoC2018\nSearching for a solution in zoeimogen/AoC2018\nSearching for a solution in awyd234/adventofcode\nSearching for a solution in muffinsofgreg/adventcode2018\nSearching for a solution in asberk/aoc18\nAbout to blindly run https://github.com/asberk/aoc18/blob/master/03.py.\nType yes if you think that's a good idea.\nHint: it's not.\nyes\nRunning it, stand back.\nIt raised an exception.\nSearching for a solution in coandco/advent2018\nSearching for a solution in ChrisDoubleEwe/AdventOfCode2018\nSearching for a solution in veeraita/advent_of_code_2018\nSearching for a solution in protocol7/advent-of-code-2018\nSearching for a solution in SpionSkummis/Advent-of-Code-2018\nAbout to blindly run https://github.com/SpionSkummis/Advent-of-Code-2018/blob/master/Erik/Day3.py.\nType yes if you think that's a good idea.\nHint: it's not.\nyes\nRunning it, stand back.\nThe number of squares cut more than once is: 119551\nThe non-overlapping square was found at nr 1124\nWas that the right answer?\nyes\n```\n"}, {"repo": "molyswu/hand_detection", "language": "Python", "readme_contents": "using Neural Networks (SSD) on Tensorflow.\n\nThis repo documents steps and scripts used to train a hand detector using Tensorflow (Object Detection API). As with any DNN based task, the most expensive (and riskiest) part of the process has to do with finding or creating the right (annotated) dataset. I was interested mainly in detecting hands on a table (egocentric view point). I experimented first with the [Oxford Hands Dataset](http://www.robots.ox.ac.uk/~vgg/data/hands/) (the results were not good). I then tried the [Egohands Dataset](http://vision.soic.indiana.edu/projects/egohands/) which was a much better fit to my requirements.\n\nThe goal of this repo/post is to demonstrate how neural networks can be applied to the (hard) problem of tracking hands (egocentric and other views). Better still, provide code that can be adapted to other uses cases.\n\nIf you use this tutorial or models in your research or project, please cite [this](#citing-this-tutorial).\n\nHere is the detector in action.\n\n<img src=\"images/hand1.gif\" width=\"33.3%\"><img src=\"images/hand2.gif\" width=\"33.3%\"><img src=\"images/hand3.gif\" width=\"33.3%\">\nRealtime detection on video stream from a webcam .\n\n<img src=\"images/chess1.gif\" width=\"33.3%\"><img src=\"images/chess2.gif\" width=\"33.3%\"><img src=\"images/chess3.gif\" width=\"33.3%\">\nDetection on a Youtube video.\n\nBoth examples above were run on a macbook pro **CPU** (i7, 2.5GHz, 16GB). Some fps numbers are:\n\n\n| FPS  | Image Size | Device| Comments|\n| ------------- | ------------- | ------------- | ------------- |\n| 21  | 320 * 240  | Macbook pro (i7, 2.5GHz, 16GB) | Run without visualizing results|\n| 16  | 320 * 240  | Macbook pro (i7, 2.5GHz, 16GB) | Run while visualizing results (image above) |\n| 11  | 640 * 480  | Macbook pro (i7, 2.5GHz, 16GB) | Run while visualizing results (image above) |\n\n> Note: The code in this repo is written and tested with Tensorflow `1.4.0-rc0`. Using a different version may result in [some errors](https://github.com/tensorflow/models/issues/1581).\nYou may need to [generate your own frozen model](https://pythonprogramming.net/testing-custom-object-detector-tensorflow-object-detection-api-tutorial/?completed=/training-custom-objects-tensorflow-object-detection-api-tutorial/) graph using the [model checkpoints](model-checkpoint) in the repo to fit your TF version.\n\n\n\n**Content of this document**\n- Motivation - Why Track/Detect hands with Neural Networks\n- Data preparation and network training in Tensorflow (Dataset, Import, Training)\n- Training the hand detection Model\n- Using the Detector to Detect/Track hands\n- Thoughts on Optimizations.\n\n> P.S if you are using or have used the models provided here, feel free to reach out on twitter ([@vykthur](https://twitter.com/vykthur)) and share your work!\n\n## Motivation - Why Track/Detect hands with Neural Networks?\n\nThere are several existing approaches to tracking hands in the computer vision domain. Incidentally, many of these approaches are rule based (e.g extracting background based on texture and boundary features, distinguishing between hands and background using color histograms and HOG classifiers,) making them not very robust. For example, these algorithms might get confused if the background is unusual or in situations where sharp changes in lighting conditions cause sharp changes in skin color or the tracked object becomes occluded.(see [here for a review](https://www.cse.unr.edu/~bebis/handposerev.pdf) paper on hand pose estimation from the HCI perspective)\n\nWith sufficiently large datasets, neural networks provide opportunity to train models that perform well and address challenges of existing object tracking/detection algorithms - varied/poor lighting, noisy environments, diverse viewpoints and even occlusion. The main drawbacks to usage for real-time tracking/detection is that they can be complex, are relatively slow compared to tracking-only algorithms and it can be quite expensive to assemble a good dataset. But things are changing with advances in fast neural networks.\n\nFurthermore, this entire area of work has been made more approachable by deep learning frameworks (such as the tensorflow object detection api) that simplify the process of training a model for custom object detection. More importantly, the advent of fast neural network models like ssd, faster r-cnn, rfcn (see [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models) ) etc make neural networks an attractive candidate for real-time detection (and tracking) applications. Hopefully, this repo demonstrates this.\n\n> If you are not interested in the process of training the detector, you can skip straight to applying the [pretrained model I provide in detecting hands](#detecting-hands).\n\nTraining a model is a multi-stage process (assembling dataset, cleaning, splitting into training/test partitions and generating an inference graph). While I lightly touch on the details of these parts, there are a few other tutorials cover training a custom object detector using the tensorflow object detection api in more detail[ see [here](https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/) and [here](https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9) ]. I recommend you walk through those if interested in training a custom object detector from scratch.\n\n## Data preparation and network training in Tensorflow (Dataset, Import, Training)\n\n**The Egohands Dataset**\n\nThe hand detector model is built using data from the [Egohands Dataset](http://vision.soic.indiana.edu/projects/egohands/) dataset. This dataset works well for several reasons. It contains high quality, pixel level annotations (>15000 ground truth labels) where hands are located across 4800 images. All images are captured from an egocentric view (Google glass) across 48 different environments (indoor, outdoor) and activities (playing cards, chess, jenga, solving puzzles etc).\n\n<img src=\"images/egohandstrain.jpg\" width=\"100%\">\n\nIf you will be using the Egohands dataset, you can cite them as follows:\n\n> Bambach, Sven, et al. \"Lending a hand: Detecting hands and recognizing activities in complex egocentric interactions.\" Proceedings of the IEEE International Conference on Computer Vision. 2015.\n\nThe Egohands dataset (zip file with labelled data) contains 48 folders of locations where video data was collected (100 images per folder).\n```\n-- LOCATION_X\n  -- frame_1.jpg\n  -- frame_2.jpg\n  ...\n  -- frame_100.jpg\n  -- polygons.mat  // contains annotations for all 100 images in current folder\n-- LOCATION_Y\n  -- frame_1.jpg\n  -- frame_2.jpg\n  ...\n  -- frame_100.jpg\n  -- polygons.mat  // contains annotations for all 100 images in current folder\n  ```\n\n**Converting data to Tensorflow Format**\n\nSome initial work needs to be done to the Egohands dataset to transform it into the format (`tfrecord`) which Tensorflow needs to train a model. This repo contains `egohands_dataset_clean.py` a script that will help you generate these csv files.\n\n- Downloads the egohands datasets\n- Renames all files to include their directory names to ensure each filename is unique\n- Splits the dataset into train (80%), test (10%) and eval (10%) folders.\n- Reads in `polygons.mat` for each folder, generates bounding boxes and visualizes them to ensure correctness (see image above).\n- Once the script is done running, you should have an images folder containing three folders - train, test and eval. Each of these folders should also contain a csv label document each - `train_labels.csv`, `test_labels.csv`  that can be used to generate `tfrecords`\n\nNote: While the egohands dataset provides four separate labels for hands (own left, own right, other left, and other right), for my purpose, I am only interested in the general `hand` class and label all training data as `hand`. You can modify the data prep script to generate `tfrecords` that support 4 labels.\n\nNext: convert your dataset + csv files to tfrecords. A helpful guide on this can be found [here](https://pythonprogramming.net/creating-tfrecord-files-tensorflow-object-detection-api-tutorial/).For each folder, you should be able to generate  `train.record`, `test.record` required in the training process.\n\n\n## Training the hand detection Model\n\nNow that the dataset has been assembled (and your tfrecords), the next task is to train a model based on this. With neural networks, it is possible to use a process called [transfer learning](https://www.tensorflow.org/tutorials/image_retraining) to shorten the amount of time needed to train the entire model. This means we can take an existing model (that has been trained well on a related domain (here image classification) and retrain its final layer(s) to detect hands for us. Sweet!. Given that neural networks sometimes have thousands or millions of parameters that can take weeks or months to train, transfer learning helps shorten training time to possibly hours. Tensorflow does offer a few models (in the tensorflow [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models)) and I chose to use the `ssd_mobilenet_v1_coco` model as my start point given it is currently (one of) the fastest models (read the SSD research [paper here](https://arxiv.org/pdf/1512.02325.pdf)). The training process can be done locally on your CPU machine which may take a while or better on a (cloud) GPU machine (which is what I did). For reference, training on my macbook pro (tensorflow compiled from source to take advantage of the mac's cpu architecture) the maximum speed I got was 5 seconds per step as opposed to the ~0.5 seconds per step I got with a GPU. For reference it would take about 12 days to run 200k steps on my mac (i7, 2.5GHz, 16GB) compared to ~5hrs on a GPU.\n\n> **Training on your own images**: Please use the [guide provided by Harrison from pythonprogramming](https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/) on how to generate tfrecords given your label csv files and your images. The guide also covers how to start the training process if training locally. [see [here] (https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/)]. If training in the cloud using a service like GCP, see the [guide here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_cloud.md).\n\nAs the training process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout). By observing the tensorboard graphs for total loss(see image below), it should be possible to get an idea of when the training process is complete (total loss does not decrease with further iterations/steps). I ran my training job for 200k steps (took about 5 hours) and stopped at a total Loss (errors) value of 2.575.(In retrospect, I could have stopped the training at about 50k steps and gotten a similar total loss value). With tensorflow, you can also run an evaluation concurrently that assesses your model to see how well it performs on the test data. A commonly used metric for performance is mean average precision (mAP) which is single number used to summarize the area under the precision-recall curve.  mAP is a measure of how well the model generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset. For the hand detector trained here, the mAP value was **0.9686@0.5IOU**. mAP values range from 0-1, the higher the better.  \n\n\n<img src=\"images/accuracy.jpg\" width=\"100%\">\n\nOnce training is completed, the trained inference graph (`frozen_inference_graph.pb`) is then exported (see the earlier referenced guides for how to do this) and saved in the `hand_inference_graph` folder. Now its time to do some interesting detection.\n\n## Using the Detector to Detect/Track hands\n\n\nIf you have not done this yet, please following the guide on installing [Tensorflow and the Tensorflow object detection api](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md). This will walk you through setting up the tensorflow framework, cloning the tensorflow github repo and a guide on  \n\n- Load the `frozen_inference_graph.pb` trained on the hands dataset as well as the corresponding label map. In this repo, this is done in the `utils/detector_utils.py` script by the `load_inference_graph` method.\n  ```python\n  detection_graph = tf.Graph()\n    with detection_graph.as_default():\n        od_graph_def = tf.GraphDef()\n        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n            serialized_graph = fid.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n        sess = tf.Session(graph=detection_graph)\n    print(\">  ====== Hand Inference graph loaded.\")\n  ```\n- Detect hands. In this repo, this is done in the `utils/detector_utils.py` script by the `detect_objects` method.\n  ```python\n  (boxes, scores, classes, num) = sess.run(\n        [detection_boxes, detection_scores,\n            detection_classes, num_detections],\n        feed_dict={image_tensor: image_np_expanded})\n  ```\n- Visualize detected bounding detection_boxes. In this repo, this is done in the `utils/detector_utils.py` script by the `draw_box_on_image` method.\n\n\nThis repo contains two scripts that tie all these steps together.\n\n- detect_multi_threaded.py : A threaded implementation for reading camera video input detection and detecting. Takes a set of command line flags to set parameters such as `--display` (visualize detections), image parameters `--width` and `--height`, videe `--source` (0 for camera) etc.\n- detect_single_threaded.py : Same as above, but single threaded. This script works for video files by setting the video source parameter videe `--source` (path to a video file).\n\n\n```cmd\n  # load and run detection on video at path \"videos/chess.mov\"\n  python detect_single_threaded.py --source videos/chess.mov\n```\n\n> Update: If you do have errors loading the frozen inference graph in this repo, feel free to generate a new graph that fits your TF version from the model-checkpoint in this repo.\nUse the [export_inference_graph.py](https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py) script provided in the tensorflow object detection api repo.\nMore guidance on this [here](https://pythonprogramming.net/testing-custom-object-detector-tensorflow-object-detection-api-tutorial/?completed=/training-custom-objects-tensorflow-object-detection-api-tutorial/).\n\n## Thoughts on Optimization.\nA few things that led to noticeable performance increases.\n\n- Threading: Turns out that reading images from a webcam is a heavy I/O event and if run on the main application thread can slow down the program. I implemented some good ideas from [Adrian Rosebuck](https://www.pyimagesearch.com/2017/02/06/faster-video-file-fps-with-cv2-videocapture-and-opencv/) on parrallelizing image capture across multiple worker threads. This mostly led to an FPS increase of about 5 points.\n- For those new to Opencv, images from the `cv2.read()` method return images in [BGR format](https://www.learnopencv.com/why-does-opencv-use-bgr-color-format/). Ensure you convert to RGB before detection (accuracy will be much reduced if you dont).\n```python\ncv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n```\n- Keeping your input image small will increase fps without any significant accuracy drop.(I used about 320 x 240 compared to the 1280 x 720 which my webcam provides).\n\n- Model Quantization. Moving from the current 32 bit to 8 bit can achieve up to 4x reduction in memory required to load and store models. One way to further speed up this model is to explore the use of [8-bit fixed point quantization](https://heartbeat.fritz.ai/8-bit-quantization-and-tensorflow-lite-speeding-up-mobile-inference-with-low-precision-a882dfcafbbd).\n\nPerformance can also be increased by a clever combination of tracking algorithms with the already decent detection and this is something I am still experimenting with. Have ideas for optimizing better, please share!\n\n<img src=\"images/general.jpg\" width=\"100%\">\nNote: The detector does reflect some limitations associated with the training set. This includes non-egocentric viewpoints, very noisy backgrounds (e.g in a sea of hands) and sometimes skin tone.  There is opportunity to improve these with additional data.\n\n\n## Integrating Multiple DNNs.\n\nOne way to make things more interesting is to integrate our new knowledge of where \"hands\" are with other detectors trained to recognize other objects. Unfortunately, while our hand detector can in fact detect hands, it cannot detect other objects (a factor or how it is trained). To create a detector that classifies multiple different objects would mean a long involved process of assembling datasets for each class and a lengthy training process.  \n\n> Given the above, a potential strategy is to explore structures that allow us **efficiently** interleave output form multiple pretrained models for various object classes and have them detect multiple objects on a single image.  \n\nAn example of this is with my primary use case where I am interested in understanding the position of objects on a table with respect to hands on same table. I am currently doing some work on a threaded application that loads multiple detectors and outputs bounding boxes on a single image. More on this soon.\n\n## Acknowledgements\n\nThis work also served as an intense weekend crash course for me to learn Python and Tensorflow. It would be impossible without the Egohands Dataset, many thanks to the authors! The tensorflow custom object detection guides by [Harrison from pythonprogramming](https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/) and [Dat Tran](https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9) were immensely helpful to this learning process. And ofcourse, many thanks to the Tensorflow authors! Its a great frameworks!\n\n\n\n\nIf you have created something cool, send me a note (or tweet) and I'll be happy to include it here!\n\n## Citing this tutorial\n\nIf you'd like to cite this work, use the below.\n\nVictor Dibia, Real-time Hand-Detection using Neural Networks (SSD) on Tensorflow, (2017), GitHub repository, https://github.com/victordibia/handtracking\n```bib\n"}]